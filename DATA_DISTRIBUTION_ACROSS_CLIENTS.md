# Data Distribution Across Clients in Blockchain Federated Learning

## ğŸ¯ **Overview**

The system implements **3 different data distribution strategies** for federated learning clients, with the current implementation using **Dirichlet distribution** for realistic non-IID scenarios.

---

## ğŸ“Š **Data Distribution Methods**

### **1. IID Distribution (Independent and Identically Distributed)**

```python
def distribute_data(self, train_data, train_labels, distribution_type='iid'):
    # Random split - each client gets random samples
    indices = torch.randperm(len(train_data))
    samples_per_client = len(train_data) // self.num_clients

    for i, client in enumerate(self.clients):
        start_idx = i * samples_per_client
        end_idx = start_idx + samples_per_client
        client_data = train_data[indices[start_idx:end_idx]]
        client_labels = train_labels[indices[start_idx:end_idx]]
```

**Characteristics:**

- **Equal samples per client**
- **Random distribution** of all classes
- **Same class proportions** across clients
- **Unrealistic** for real federated learning

### **2. Non-IID Distribution (Simple)**

```python
def distribute_data(self, train_data, train_labels, distribution_type='non_iid'):
    # Split by class - each client gets specific classes
    unique_labels = torch.unique(train_labels)
    samples_per_class = len(train_data) // len(unique_labels)
    samples_per_client_per_class = samples_per_class // self.num_clients
```

**Characteristics:**

- **Class-based splitting**
- **Each client gets specific classes**
- **High heterogeneity**
- **Too extreme** for realistic scenarios

### **3. Dirichlet Distribution (Current Implementation)**

```python
def distribute_data_with_dirichlet(self, train_data, train_labels, alpha=1.0):
    # Realistic non-IID using Dirichlet distribution
    for label in unique_labels:
        dirichlet_dist = np.random.dirichlet([alpha] * self.num_clients)
        dirichlet_distributions[label.item()] = dirichlet_dist
```

**Characteristics:**

- **Realistic heterogeneity**
- **Configurable via Î± parameter**
- **Each client gets different class proportions**
- **Most realistic** for federated learning

---

## ğŸ” **Current Data Distribution Analysis**

### **From System Output:**

```
2025-09-17 13:17:18,719 - INFO - Total samples: 56,000, Classes: 1
2025-09-17 13:17:18,720 - INFO - Class 0: Dirichlet distribution = [0.41540175 0.47988724 0.10471102]

Client client_1: 23,262 total samples
  Class distribution: {0: 23262}
Client client_2: 26,873 total samples
  Class distribution: {0: 26873}
Client client_3: 5,863 total samples
  Class distribution: {0: 5863}
```

### **ğŸš¨ Current Problem:**

- **Only 1 class** (Class 0 = Normal) instead of 2 classes
- **No attack samples** in training data
- **Dirichlet distribution** can't work properly with 1 class

---

## ğŸ“ˆ **Expected Data Distribution (After Fix)**

### **With 2 Classes (Normal + Attack):**

#### **Dirichlet Distribution (Î± = 1.0):**

```
Class 0 (Normal): Dirichlet distribution = [0.3, 0.4, 0.3]
Class 1 (Attack): Dirichlet distribution = [0.2, 0.5, 0.3]

Client 1: 16,800 Normal + 11,200 Attack = 28,000 samples
  Class distribution: {0: 16800, 1: 11200}
  Heterogeneity (std): 0.15

Client 2: 22,400 Normal + 28,000 Attack = 50,400 samples
  Class distribution: {0: 22400, 1: 28000}
  Heterogeneity (std): 0.25

Client 3: 16,800 Normal + 16,800 Attack = 33,600 samples
  Class distribution: {0: 16800, 1: 16800}
  Heterogeneity (std): 0.0
```

---

## ğŸ›ï¸ **Dirichlet Distribution Parameters**

### **Î± Parameter Effects:**

| **Î± Value**  | **Heterogeneity** | **Description**    | **Use Case**        |
| ------------ | ----------------- | ------------------ | ------------------- |
| **Î± = 0.1**  | **Very High**     | Extreme non-IID    | Stress testing      |
| **Î± = 0.5**  | **High**          | High heterogeneity | Realistic scenarios |
| **Î± = 1.0**  | **Moderate**      | Balanced non-IID   | **RECOMMENDED**     |
| **Î± = 5.0**  | **Low**           | Low heterogeneity  | Near-IID baseline   |
| **Î± = 10.0** | **Very Low**      | Near-IID           | IID comparison      |

### **Current Setting: Î± = 1.0**

- **Moderate heterogeneity**
- **Good balance** between IID and extreme non-IID
- **Realistic** for federated learning scenarios
- **Suitable** for zero-day detection experiments

---

## ğŸ”„ **Data Distribution Flow**

### **Step 1: Data Preparation**

```
Original UNSW-NB15 Data:
â”œâ”€â”€ Training: 175,341 samples Ã— 45 features
â”œâ”€â”€ Testing: 82,332 samples Ã— 45 features
â””â”€â”€ Classes: 10 (Normal + 9 attack types)
```

### **Step 2: Zero-Day Split**

```
Training Data (After Zero-Day Split):
â”œâ”€â”€ Normal samples: ~28,000
â”œâ”€â”€ Attack samples: ~28,000 (8 attack types, exclude zero-day)
â””â”€â”€ Binary labels: 0=Normal, 1=Attack
```

### **Step 3: Dirichlet Distribution**

```
For each class (Normal, Attack):
â”œâ”€â”€ Generate Dirichlet distribution: [Î±, Î±, Î±] â†’ [p1, p2, p3]
â”œâ”€â”€ Calculate samples per client: p_i Ã— class_samples
â””â”€â”€ Randomly sample from class for each client
```

### **Step 4: Client Assignment**

```
Client 1: Gets p1_normal Ã— normal_samples + p1_attack Ã— attack_samples
Client 2: Gets p2_normal Ã— normal_samples + p2_attack Ã— attack_samples
Client 3: Gets p3_normal Ã— normal_samples + p3_attack Ã— attack_samples
```

---

## ğŸ“Š **Visualization of Distribution**

### **Current (Wrong) Distribution:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Class 0 (Normal)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Client 1  â”‚  â”‚   Client 2  â”‚  â”‚   Client 3  â”‚        â”‚
â”‚  â”‚   41.5%     â”‚  â”‚   48.0%     â”‚  â”‚   10.5%     â”‚        â”‚
â”‚  â”‚  23,262     â”‚  â”‚  26,873     â”‚  â”‚   5,863     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Expected (Correct) Distribution:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Class 0 (Normal)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Client 1  â”‚  â”‚   Client 2  â”‚  â”‚   Client 3  â”‚        â”‚
â”‚  â”‚    30%      â”‚  â”‚    40%      â”‚  â”‚    30%      â”‚        â”‚
â”‚  â”‚  16,800     â”‚  â”‚  22,400     â”‚  â”‚  16,800     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Class 1 (Attack)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   Client 1  â”‚  â”‚   Client 2  â”‚  â”‚   Client 3  â”‚        â”‚
â”‚  â”‚    20%      â”‚  â”‚    50%      â”‚  â”‚    30%      â”‚        â”‚
â”‚  â”‚  11,200     â”‚  â”‚  28,000     â”‚  â”‚  16,800     â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ **Impact on Federated Learning**

### **Current Impact (Wrong Distribution):**

- **No attack patterns learned** during training
- **Poor zero-day detection** performance
- **Unrealistic scenario** for security applications
- **Dirichlet distribution meaningless** with 1 class

### **Expected Impact (Correct Distribution):**

- **Mixed attack patterns** learned by each client
- **Realistic non-IID** federated learning
- **Better zero-day detection** with learned attack knowledge
- **Proper heterogeneity** for algorithm evaluation

---

## ğŸ”§ **How to Fix Data Distribution**

### **Step 1: Fix Zero-Day Split Logic**

```python
# In blockchain_federated_unsw_preprocessor.py
# Ensure attack samples are included in training data
train_mask = (train_df['label'] == 0) | (train_df['label'] != zero_day_id)
# This should include Normal + 8 attack types (exclude only zero-day)
```

### **Step 2: Verify Binary Label Creation**

```python
# Ensure binary labels are created correctly
train_df['binary_label'] = (train_df['label'] != 0).astype(int)
# 0 = Normal, 1 = Attack (all attack types)
```

### **Step 3: Test Distribution**

```python
# Run system and verify 2-class distribution
python src/main.py
# Should show: "Classes: 2" instead of "Classes: 1"
```

---

## ğŸ“‹ **Summary**

The data distribution system is **well-designed** but currently **broken** due to the zero-day split issue:

1. **âœ… Dirichlet distribution** is properly implemented
2. **âœ… Î± = 1.0** provides good heterogeneity
3. **âœ… Multiple distribution methods** available
4. **âŒ Zero-day split** excludes all attack samples
5. **âŒ Only 1 class** in training data
6. **âŒ Dirichlet distribution** can't work with 1 class

**Fix the zero-day split logic** and you'll get realistic non-IID federated learning with proper data distribution across clients!
