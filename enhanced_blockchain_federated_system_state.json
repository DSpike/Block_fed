{
  "config": {
    "data_path": "UNSW_NB15_training-set.csv",
    "test_path": "UNSW_NB15_testing-set.csv",
    "zero_day_attack": "DoS",
    "input_dim": 57,
    "hidden_dim": 128,
    "embedding_dim": 64,
    "support_weight": 0.3,
    "test_weight": 0.7,
    "num_clients": 3,
    "num_rounds": 20,
    "local_epochs": 9,
    "learning_rate": 0.001,
    "ethereum_rpc_url": "http://localhost:8545",
    "contract_address": "0x74f2D28CEC2c97186dE1A02C1Bae84D19A7E8BC8",
    "incentive_contract_address": "0x02090bbB57546b0bb224880a3b93D2Ffb0dde144",
    "private_key": "0x4f3edf983ac636a65a842ce7c78d9aa706d3b113bce9c46f30d7d21715b23b1d",
    "aggregator_address": "0x4565f36D8E3cBC1c7187ea39Eb613E484411e075",
    "ipfs_url": "http://localhost:5001",
    "enable_incentives": true,
    "base_reward": 100,
    "max_reward": 1000,
    "min_reputation": 100,
    "device": "cuda",
    "fully_decentralized": false
  },
  "training_history": [
    {
      "round": 1,
      "timestamp": 1760177170.0574377,
      "accuracy": 0.473,
      "client_updates": [
        "ClientUpdate(client_id='client_1', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0879, -0.0983, -0.1084,  ..., -0.0154, -0.0448,  0.1125],\n        [-0.1128, -0.0005,  0.0792,  ...,  0.0438,  0.0141, -0.0348],\n        [ 0.0862, -0.1035,  0.1256,  ..., -0.0028, -0.1117, -0.0507],\n        ...,\n        [-0.1115,  0.0008, -0.0611,  ...,  0.0540,  0.0103, -0.0440],\n        [-0.1353, -0.0928,  0.0671,  ...,  0.0646,  0.1113, -0.0247],\n        [ 0.0605,  0.1018, -0.0286,  ...,  0.0010,  0.0770,  0.0920]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0216, -0.1104,  0.0138,  0.0990,  0.1285,  0.1155,  0.0579,  0.0265,\n         0.0351, -0.0125, -0.0634, -0.1380,  0.0122, -0.0095,  0.0752,  0.0534,\n        -0.0919,  0.0099,  0.0313,  0.0552,  0.0361, -0.0339, -0.0636, -0.0016,\n        -0.0571,  0.0606,  0.0633,  0.0671,  0.0765, -0.0538, -0.1192, -0.1067,\n        -0.0693,  0.0637,  0.1291,  0.0084, -0.0198, -0.0963,  0.0456, -0.0396,\n        -0.0222, -0.0213,  0.0109,  0.0525, -0.0196, -0.0975, -0.0656,  0.1080,\n        -0.0358, -0.1035,  0.0005,  0.0594,  0.0310, -0.0882,  0.0540, -0.0561,\n         0.0407,  0.0564, -0.0135,  0.0295,  0.0104, -0.0006,  0.0204,  0.0006,\n        -0.1153, -0.0694,  0.1078, -0.0771, -0.0667,  0.0302, -0.0740, -0.0162,\n        -0.0739, -0.0464, -0.1301,  0.0243,  0.1055,  0.0044, -0.0213,  0.0058,\n        -0.0550,  0.1224, -0.0869, -0.0616,  0.1133, -0.0457,  0.0745, -0.0790,\n         0.0413, -0.0595, -0.0133, -0.1267,  0.0854, -0.1418,  0.0252, -0.0738,\n        -0.0063,  0.1143,  0.0991,  0.0547, -0.0472, -0.0492,  0.0227,  0.0294,\n        -0.1305, -0.1040,  0.1123, -0.0375, -0.0505, -0.0293,  0.0901, -0.1117,\n         0.0859, -0.1274, -0.0794, -0.0409, -0.1269, -0.1095, -0.0226, -0.0850,\n         0.0754,  0.0605,  0.1115,  0.0561,  0.0025,  0.0332, -0.0815,  0.0385]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.1260, -0.0424, -0.0085,  ..., -0.0397, -0.0462, -0.0447],\n        [ 0.0197, -0.0825,  0.1339,  ..., -0.0590,  0.0332, -0.0920],\n        [ 0.0413, -0.0165, -0.1112,  ..., -0.0562, -0.0873, -0.0953],\n        ...,\n        [-0.0961,  0.0473,  0.0833,  ..., -0.1153, -0.0818, -0.1291],\n        [-0.1402,  0.0917,  0.1094,  ...,  0.0597, -0.0377,  0.0365],\n        [-0.0297,  0.0673, -0.0735,  ...,  0.1179, -0.1266,  0.0057]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.0990, -0.0499, -0.1303, -0.0585, -0.0045, -0.0045,  0.0734,  0.1034,\n        -0.1158, -0.0559, -0.0228, -0.0882, -0.1131,  0.0524, -0.0442,  0.1203,\n         0.0697, -0.0632,  0.0263,  0.0563, -0.1049, -0.1019,  0.1077,  0.0169,\n        -0.0938,  0.0712, -0.1194, -0.0048,  0.0210, -0.0877,  0.0704,  0.0466,\n         0.0542,  0.0572, -0.0487,  0.0538, -0.1134,  0.0187,  0.0711,  0.0671,\n         0.0630, -0.1147, -0.1133, -0.0797,  0.0680,  0.0260, -0.1044, -0.0466,\n         0.0844,  0.0324,  0.0926, -0.0902, -0.0940, -0.0218,  0.0023, -0.0929,\n         0.0442,  0.0469,  0.0926, -0.0967, -0.1072, -0.0266,  0.0634,  0.0685]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0035,  0.1096, -0.0684,  ...,  0.0547, -0.0403, -0.0109],\n        [ 0.0886, -0.1229,  0.0126,  ...,  0.0803,  0.0715, -0.1239],\n        [ 0.0899, -0.0721, -0.1129,  ..., -0.0096, -0.0725,  0.0964],\n        ...,\n        [-0.0570, -0.0908, -0.0285,  ...,  0.0188, -0.0946, -0.0265],\n        [ 0.0530, -0.0184,  0.0521,  ..., -0.0681,  0.1358, -0.0396],\n        [-0.1210,  0.0868, -0.0879,  ...,  0.0553, -0.0256, -0.0821]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 0.0890, -0.0718, -0.0640, -0.1164, -0.1188,  0.0452,  0.0565, -0.0751,\n         0.0163,  0.1172, -0.0357,  0.0236, -0.1274, -0.0957, -0.1117, -0.0774,\n         0.0025, -0.0186, -0.1135, -0.1047,  0.0315,  0.1373, -0.1096, -0.1346,\n         0.0072,  0.0955, -0.0463,  0.0873,  0.0357,  0.0409,  0.0696,  0.1072,\n         0.0430, -0.0134, -0.1231, -0.1306,  0.0302,  0.0047, -0.0265, -0.0273,\n        -0.1122,  0.1287,  0.0921,  0.1394, -0.0127, -0.1321, -0.0271,  0.0755,\n         0.0339, -0.1277,  0.0895, -0.0107,  0.0764, -0.1073,  0.0759,  0.0619,\n         0.0428,  0.0414, -0.0728, -0.0609, -0.0224, -0.1137,  0.0249, -0.0389,\n         0.0539, -0.0424, -0.1039,  0.0401, -0.0161,  0.0949,  0.0557, -0.0401,\n         0.0957,  0.0838,  0.0631,  0.0026,  0.0069, -0.0616, -0.1183, -0.0277,\n         0.0520,  0.1104,  0.0886, -0.0419, -0.0418,  0.1117, -0.0177, -0.1100,\n         0.0418, -0.0572,  0.1166, -0.0015, -0.0472,  0.0615, -0.0138, -0.0928,\n         0.0217, -0.1290,  0.0415, -0.0791,  0.0916,  0.0187, -0.0611, -0.0605,\n        -0.0268, -0.1120, -0.0823,  0.0516,  0.0429,  0.0990,  0.1090, -0.1161,\n         0.0142,  0.1093, -0.0695,  0.0610,  0.1079,  0.0937, -0.0931, -0.1246,\n         0.0941, -0.0428, -0.0347, -0.0504, -0.0420,  0.0102,  0.0251,  0.0374,\n        -0.0336, -0.0083, -0.0301, -0.1381,  0.0308,  0.0305, -0.1234, -0.1238,\n        -0.0005,  0.0370,  0.0200, -0.0994,  0.0643, -0.0580, -0.0104, -0.0128,\n         0.0720,  0.0813, -0.1053,  0.0077, -0.0267,  0.0773, -0.0137, -0.0823,\n         0.0769, -0.0730,  0.1057, -0.0434, -0.0521, -0.0153, -0.0973,  0.0200,\n         0.0513,  0.0321,  0.0725,  0.0208,  0.0530, -0.1267,  0.0108, -0.1009,\n         0.0140, -0.1307,  0.0590,  0.0844,  0.0143,  0.1025, -0.0209,  0.0552,\n         0.1227,  0.0910, -0.0862, -0.0091,  0.0929, -0.1110,  0.1121,  0.0171,\n         0.0209, -0.0841, -0.1028, -0.0404,  0.0668,  0.0102, -0.0169, -0.0289,\n        -0.0503,  0.1101, -0.0711,  0.0870,  0.0089,  0.0074, -0.1148,  0.0374,\n        -0.0200, -0.0933,  0.0339,  0.0660, -0.0306, -0.1229, -0.1009, -0.1002,\n        -0.0525, -0.0025,  0.0605,  0.0143, -0.0353,  0.0878, -0.0963,  0.0829,\n        -0.0320,  0.0371,  0.0803,  0.0028,  0.0317,  0.0798, -0.0548, -0.0977,\n        -0.0378,  0.0715, -0.0876,  0.0772, -0.1187, -0.0621, -0.0449, -0.0722,\n        -0.0069, -0.1036, -0.1060, -0.0268, -0.0375, -0.0187,  0.1465, -0.1173,\n        -0.0672,  0.0275,  0.0596, -0.0533, -0.0678,  0.1183,  0.0433, -0.1229,\n         0.0321,  0.0460,  0.0393, -0.0689,  0.0996,  0.0882, -0.1214,  0.1122]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[-0.0416,  0.0018, -0.0476,  ..., -0.0232,  0.0044,  0.0020],\n        [-0.0381,  0.0325, -0.0284,  ..., -0.0076, -0.0125, -0.0417],\n        [ 0.0270, -0.0408, -0.0108,  ..., -0.0118, -0.0234,  0.0375],\n        ...,\n        [ 0.0139, -0.0376,  0.0364,  ...,  0.0116, -0.0087, -0.0304],\n        [ 0.0008, -0.0118, -0.0015,  ..., -0.0289,  0.0422,  0.0311],\n        [ 0.0249,  0.0186, -0.0057,  ...,  0.0134, -0.0150,  0.0242]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0146,  0.0231,  0.0350, -0.0174,  0.0390, -0.0195, -0.0219, -0.0350,\n        -0.0348,  0.0302, -0.0191, -0.0147, -0.0499,  0.0213, -0.0075, -0.0491,\n         0.0432, -0.0172, -0.0521, -0.0321, -0.0230, -0.0398,  0.0016, -0.0053,\n        -0.0378,  0.0353,  0.0207, -0.0372, -0.0031, -0.0145,  0.0164, -0.0291,\n        -0.0381,  0.0087,  0.0369,  0.0534, -0.0285, -0.0032, -0.0404,  0.0352,\n        -0.0084,  0.0435, -0.0172,  0.0317,  0.0200,  0.0215,  0.0429,  0.0363,\n        -0.0412, -0.0576,  0.0258,  0.0366,  0.0414,  0.0138,  0.0147, -0.0517,\n         0.0132,  0.0030,  0.0523,  0.0219, -0.0150,  0.0252,  0.0077,  0.0530]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.1038,  0.1191, -0.0514,  ..., -0.0309,  0.0552, -0.0169],\n        [ 0.0388, -0.1021,  0.0907,  ...,  0.1081,  0.0510, -0.0211],\n        [ 0.0765, -0.1078,  0.0652,  ..., -0.0564, -0.0068, -0.0773],\n        ...,\n        [ 0.0151,  0.0403, -0.0043,  ...,  0.0499,  0.1053,  0.0555],\n        [ 0.0682,  0.0018, -0.0380,  ...,  0.0047,  0.0923,  0.0118],\n        [-0.0924, -0.1193, -0.0202,  ...,  0.0476,  0.1172,  0.0024]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0719,  0.0435,  0.1006,  0.1101,  0.0164,  0.0071,  0.0815,  0.0461,\n         0.0628, -0.0900,  0.0449, -0.1178,  0.1205,  0.0784,  0.0156,  0.0581,\n        -0.0579,  0.0244,  0.0787, -0.0475, -0.0440, -0.0555, -0.1197,  0.0173,\n         0.0019,  0.0526, -0.0962, -0.0861, -0.0515, -0.0067, -0.1214, -0.1017,\n         0.0586,  0.1215, -0.0311, -0.0489,  0.0136,  0.0617, -0.0688, -0.0635,\n        -0.0850,  0.0893,  0.0137,  0.0921, -0.0849,  0.0165, -0.0381, -0.0315,\n        -0.0321, -0.0334, -0.0935, -0.0900,  0.0591, -0.1196,  0.1119,  0.0913,\n        -0.1039, -0.1243, -0.0536, -0.1209, -0.0803,  0.1005,  0.0951,  0.1245]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0974,  0.1151,  0.0976,  ...,  0.1224,  0.0041, -0.1076],\n        [ 0.1032, -0.0141,  0.1151,  ...,  0.0876,  0.0076, -0.0541],\n        [ 0.0067, -0.0825,  0.0349,  ...,  0.1243, -0.0359,  0.1196],\n        ...,\n        [ 0.0663,  0.0538,  0.0807,  ...,  0.0382, -0.0558, -0.1114],\n        [-0.0350,  0.1133,  0.0544,  ..., -0.0886, -0.0346, -0.0547],\n        [ 0.0010, -0.0708,  0.0124,  ...,  0.0224, -0.0921,  0.0909]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0170, -0.1190, -0.0163,  0.0180,  0.0892,  0.0154, -0.0432,  0.0846,\n        -0.0632,  0.1190,  0.0324, -0.1167, -0.0533, -0.0249, -0.0842,  0.0072,\n        -0.0665, -0.0642, -0.0509, -0.0306, -0.0569, -0.0734,  0.0363, -0.1180,\n        -0.0476, -0.0459,  0.0091, -0.0347,  0.0326, -0.0486,  0.1146,  0.0865]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-8.9725e-03, -5.6232e-02,  5.2653e-02, -1.0070e-01,  8.0529e-02,\n         -1.2664e-01,  4.5819e-02,  6.7861e-02,  1.0253e-01,  8.7408e-02,\n         -8.5727e-02,  4.1961e-02, -7.0783e-02, -1.2807e-02, -8.5416e-02,\n         -5.6530e-02, -2.2912e-02, -1.1165e-01,  1.5820e-01,  1.1725e-01,\n         -1.2391e-01, -1.5837e-01,  1.5850e-01, -9.2231e-02,  3.6164e-02,\n         -1.6964e-02, -1.4230e-01,  5.0439e-02,  1.7090e-04, -9.7547e-03,\n         -1.2355e-02, -3.5148e-02],\n        [ 2.8916e-02,  1.5201e-01,  1.6005e-01, -1.4041e-01,  1.1725e-01,\n          6.2444e-02, -8.5904e-02, -2.4250e-02,  9.0298e-02,  8.4217e-02,\n          1.7155e-01, -6.6788e-02,  4.1148e-02, -2.5535e-02, -1.1825e-01,\n          5.1646e-02, -1.1305e-01, -3.8224e-02, -1.7274e-01,  1.6546e-01,\n         -1.8081e-02,  6.2844e-02, -1.7437e-02, -6.8348e-02, -2.0858e-02,\n         -2.3944e-03, -1.6186e-01, -1.7271e-01,  1.3139e-01,  1.2958e-01,\n          1.6581e-01,  4.1241e-02]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([ 0.0736, -0.0948]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[-0.0955,  0.0147, -0.1319,  ...,  0.1331,  0.0950,  0.0238],\n        [ 0.0489,  0.1033,  0.0389,  ..., -0.1113,  0.1426,  0.1309],\n        [-0.1468, -0.1501,  0.1562,  ..., -0.1024, -0.1594,  0.1520],\n        ...,\n        [ 0.0631,  0.1541,  0.1205,  ..., -0.0562, -0.1257,  0.0046],\n        [-0.1487,  0.1119,  0.0838,  ...,  0.1374,  0.1321,  0.1435],\n        [ 0.1358,  0.0151,  0.0344,  ...,  0.0302,  0.0177,  0.0243]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-9.0050e-03,  1.1500e-02,  1.3584e-02,  1.0298e-03,  1.8006e-02,\n        -1.3928e-02, -7.4694e-03, -3.0862e-03,  7.8119e-03, -2.3006e-03,\n         3.2143e-03,  1.0045e-02,  9.9374e-03,  1.5783e-02,  1.9229e-02,\n        -1.3060e-03, -1.2273e-02,  6.9244e-03,  1.2472e-02, -3.1260e-03,\n        -1.1784e-02,  1.6595e-02,  7.3127e-03, -2.5553e-02,  9.6031e-03,\n         9.4050e-03, -1.1464e-02, -2.0119e-02, -2.2851e-03,  4.9664e-03,\n        -1.1397e-03, -6.4424e-03,  4.2897e-03,  4.1433e-03, -4.5914e-03,\n         1.4828e-02, -9.7052e-03,  1.4037e-02,  1.3957e-02, -9.0176e-03,\n        -1.0232e-02,  4.9471e-03,  1.0239e-04, -4.2751e-03,  6.1601e-03,\n        -4.4996e-03, -3.5132e-03, -2.6138e-03, -4.0949e-03, -9.4962e-03,\n         3.7912e-03,  1.1590e-03, -6.7543e-03, -1.2450e-02,  7.1690e-03,\n        -9.9059e-03, -1.7896e-02,  4.6641e-04, -8.1135e-04,  2.8029e-03,\n        -1.1315e-02, -7.0623e-03, -1.5276e-02, -1.4732e-02,  2.2886e-05,\n        -2.4774e-05, -4.1303e-04,  1.0761e-04, -1.5586e-04,  1.4362e-04,\n         6.4860e-05,  1.0708e-04, -2.1934e-04, -1.1530e-05,  1.4104e-04,\n        -5.1393e-06, -5.4964e-05,  8.3964e-07, -9.3183e-05,  2.3711e-04,\n         2.4325e-04, -2.3884e-04,  6.1788e-05, -8.9066e-05, -3.5345e-04,\n         1.7529e-04,  2.2303e-04,  2.6109e-04, -2.6206e-05, -3.3817e-05,\n         4.9624e-05,  4.2354e-04, -1.2198e-05, -2.9526e-04,  1.2456e-04,\n         2.0423e-04,  7.4176e-05,  9.6113e-05, -4.9445e-04,  8.5248e-05,\n        -7.5057e-05, -1.0502e-04, -3.3270e-05,  2.4924e-04, -2.1664e-04,\n        -3.7739e-04,  1.7891e-04,  1.0783e-04,  1.1834e-04,  3.8987e-04,\n         1.0240e-04, -6.4128e-05, -1.1352e-04,  2.0268e-04, -9.9131e-05,\n        -3.5232e-04,  2.0061e-04,  4.0018e-04,  6.9594e-05,  6.2329e-06,\n         2.6872e-04,  3.1109e-04, -6.4887e-05,  1.1268e-05, -4.5238e-04,\n         4.5174e-04,  2.7277e-04, -5.7464e-05,  2.6125e-03,  6.6516e-04,\n         2.8582e-03,  1.8910e-04,  2.4239e-03, -2.5823e-03, -5.2631e-05,\n        -2.7440e-03,  9.5355e-04,  4.5861e-04, -1.2566e-03,  2.3134e-03,\n        -1.3531e-03, -1.4668e-03,  8.3788e-04, -1.5019e-03,  2.1629e-03,\n        -6.6840e-04,  6.6946e-05,  7.7338e-04,  8.4457e-04,  4.5453e-04,\n        -1.2822e-04,  3.2461e-04, -1.1624e-04, -1.0180e-03, -2.1405e-03,\n         1.4435e-03, -1.4713e-03,  7.3463e-04, -9.2383e-04,  1.6277e-03,\n        -1.4908e-03,  2.6075e-03, -9.5340e-05,  1.3485e-03,  9.9524e-04,\n        -8.8629e-04,  1.9990e-03,  3.2615e-04,  2.1000e-03,  4.4427e-05,\n        -2.4591e-05, -2.1162e-03,  2.3681e-03, -2.4830e-04, -1.4109e-04,\n        -7.8826e-04,  1.6017e-03, -3.7665e-04,  6.5781e-04, -2.5609e-03,\n         8.9963e-04, -1.6543e-03, -2.5405e-03,  3.2379e-03, -1.8345e-04,\n        -3.1555e-04,  6.5363e-06, -2.4936e-04,  1.8513e-04,  1.3795e-03,\n         5.1768e-04,  2.2104e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1260,  0.0853,  0.0829,  ...,  0.0603, -0.0693,  0.1110],\n        [ 0.0021, -0.0082,  0.1298,  ...,  0.0687,  0.0523, -0.0520],\n        [ 0.0280, -0.1105, -0.0158,  ...,  0.0598, -0.0646, -0.0709],\n        ...,\n        [-0.1033, -0.0990,  0.1022,  ..., -0.0421,  0.0551,  0.0413],\n        [ 0.0702, -0.0698,  0.0190,  ...,  0.1288,  0.0634, -0.0584],\n        [-0.0540,  0.1008,  0.0685,  ..., -0.0461, -0.0363,  0.0430]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 1.6441e-03,  3.1178e-03,  1.1114e-03, -5.2230e-04, -6.8163e-04,\n        -5.9477e-04, -7.6185e-04, -3.2887e-04, -5.8469e-04, -6.5258e-04,\n        -4.2745e-04, -6.8123e-04, -4.5999e-04, -1.6378e-03,  3.9203e-04,\n        -5.3023e-04, -4.8706e-04, -8.6496e-04, -1.9444e-04, -3.7811e-04,\n         1.2608e-03, -6.9995e-04, -5.5856e-04,  1.3781e-03, -9.9028e-04,\n         1.8305e-03,  7.1702e-04, -1.1379e-04, -1.2367e-03,  1.5471e-04,\n        -1.2382e-03, -3.0274e-04,  6.0227e-04, -5.4902e-04,  1.0103e-03,\n        -6.5300e-04, -3.5432e-04,  4.1061e-04,  1.1551e-03, -9.6426e-04,\n         8.1370e-04, -1.4641e-03, -1.1823e-03,  1.1096e-04,  6.8498e-04,\n         2.1111e-04, -1.3086e-03, -5.0767e-04, -1.2042e-04,  3.1717e-03,\n        -7.1587e-05, -1.0012e-03,  5.4784e-04, -1.3564e-03, -1.6993e-03,\n         1.5102e-03,  3.2659e-04,  6.0318e-04,  3.1393e-03,  9.6353e-04,\n        -1.2723e-03,  1.6489e-04, -1.6931e-03, -2.8087e-04]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=50150, training_loss=np.float64(0.06072074704700045), validation_accuracy=np.float64(0.903333342075348), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760177151.9735148, model_hash='cd9733baabc9621a4e61e55394b871c3d3ce7bf561e297021661736f0daab4e3', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_2', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0779, -0.0847, -0.0983,  ..., -0.0282, -0.0587,  0.1029],\n        [-0.1047,  0.0083,  0.0821,  ...,  0.0506,  0.0215, -0.0200],\n        [ 0.0959, -0.1166,  0.1056,  ...,  0.0114, -0.1009, -0.0650],\n        ...,\n        [-0.0999, -0.0090, -0.0806,  ...,  0.0589,  0.0184, -0.0409],\n        [-0.1356, -0.0753,  0.0914,  ...,  0.0760,  0.1175, -0.0323],\n        [ 0.0673,  0.0938, -0.0399,  ..., -0.0027,  0.0783,  0.0722]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0341, -0.0781,  0.0321,  0.1152,  0.1094,  0.1268,  0.0477,  0.0192,\n         0.0613,  0.0043, -0.0572, -0.1338,  0.0203, -0.0220,  0.0736,  0.0310,\n        -0.1276,  0.0052,  0.0268,  0.0705,  0.0217, -0.0383, -0.0512,  0.0098,\n        -0.0440,  0.0765,  0.0864,  0.0660,  0.0863, -0.0647, -0.1132, -0.1259,\n        -0.0720,  0.0710,  0.1048,  0.0112, -0.0114, -0.0737,  0.0483, -0.0482,\n        -0.0198, -0.0488, -0.0194,  0.0715, -0.0326, -0.1206, -0.0490,  0.1267,\n        -0.0271, -0.1090, -0.0123,  0.0761,  0.0308, -0.0614,  0.0842, -0.0380,\n         0.0558,  0.0547, -0.0327,  0.0310,  0.0139,  0.0015,  0.0272, -0.0021,\n        -0.1194, -0.0733,  0.1113, -0.0482, -0.0654,  0.0524, -0.0883, -0.0260,\n        -0.0845, -0.0608, -0.1206,  0.0240,  0.1093,  0.0305, -0.0258, -0.0164,\n        -0.0339,  0.1172, -0.0907, -0.0666,  0.1017, -0.0505,  0.0741, -0.0904,\n         0.0687, -0.0500, -0.0006, -0.1130,  0.0969, -0.1391,  0.0254, -0.0956,\n        -0.0173,  0.1318,  0.1184,  0.0511, -0.0759, -0.0169,  0.0433,  0.0390,\n        -0.1109, -0.0734,  0.1404, -0.0561, -0.0422, -0.0159,  0.0862, -0.0944,\n         0.0786, -0.1294, -0.0831, -0.0466, -0.1199, -0.1138, -0.0279, -0.0644,\n         0.0714,  0.0724,  0.1161,  0.0492, -0.0048,  0.0378, -0.1078,  0.0373]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.1190, -0.0545, -0.0174,  ..., -0.0400, -0.0493, -0.0441],\n        [ 0.0368, -0.0879,  0.1257,  ..., -0.0467,  0.0484, -0.1036],\n        [ 0.0686, -0.0115, -0.0887,  ..., -0.0272, -0.0591, -0.1052],\n        ...,\n        [-0.1065,  0.0393,  0.0698,  ..., -0.1234, -0.0917, -0.1179],\n        [-0.1368,  0.0592,  0.0814,  ...,  0.0599, -0.0360,  0.0342],\n        [-0.0385,  0.0799, -0.0581,  ...,  0.1096, -0.1356, -0.0046]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.1038, -0.0494, -0.1362, -0.0789, -0.0140, -0.0190,  0.0772,  0.0955,\n        -0.1055, -0.0456, -0.0104, -0.0867, -0.1005,  0.0745, -0.0503,  0.1210,\n         0.0769, -0.0697,  0.0354,  0.0503, -0.1046, -0.1229,  0.0907,  0.0339,\n        -0.1292,  0.0550, -0.1127, -0.0339,  0.0238, -0.0780,  0.0719,  0.0387,\n         0.0546,  0.0366, -0.0566,  0.0747, -0.1074, -0.0065,  0.0591,  0.0527,\n         0.0732, -0.0946, -0.1189, -0.0802,  0.0619,  0.0491, -0.0885, -0.0628,\n         0.0747,  0.0520,  0.1069, -0.0858, -0.1192, -0.0142,  0.0154, -0.0937,\n         0.0404,  0.0351,  0.0962, -0.0959, -0.1199, -0.0398,  0.0689,  0.0602]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0027,  0.0904, -0.0699,  ...,  0.0420, -0.0471, -0.0173],\n        [ 0.0692, -0.1267,  0.0152,  ...,  0.0659,  0.0561, -0.1356],\n        [ 0.1179, -0.0661, -0.1015,  ...,  0.0135, -0.0482,  0.1200],\n        ...,\n        [-0.0582, -0.0839, -0.0194,  ...,  0.0213, -0.0932, -0.0149],\n        [ 0.0357, -0.0109,  0.0706,  ..., -0.0811,  0.1183, -0.0210],\n        [-0.1392,  0.0672, -0.1156,  ...,  0.0439, -0.0424, -0.0871]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 0.0829, -0.0562, -0.0801, -0.1046, -0.1148,  0.0816,  0.0619, -0.0623,\n         0.0092,  0.1205, -0.0584,  0.0610, -0.1238, -0.1026, -0.1238, -0.0877,\n        -0.0009,  0.0032, -0.1309, -0.0767,  0.0364,  0.1137, -0.1284, -0.1367,\n         0.0297,  0.0987, -0.0272,  0.0934,  0.0321,  0.0183,  0.0623,  0.1043,\n         0.0477, -0.0162, -0.1155, -0.1126,  0.0351, -0.0128, -0.0266, -0.0223,\n        -0.1101,  0.1295,  0.0735,  0.1360, -0.0220, -0.1160, -0.0332,  0.0853,\n         0.0495, -0.1068,  0.0972, -0.0559,  0.0739, -0.1028,  0.0779,  0.0402,\n         0.0634,  0.0564, -0.0711, -0.0333, -0.0042, -0.0945,  0.0375, -0.0514,\n         0.0550, -0.0382, -0.1031,  0.0358, -0.0525,  0.0927,  0.0437, -0.0366,\n         0.0891,  0.0747,  0.0600, -0.0004, -0.0028, -0.0486, -0.1138, -0.0190,\n         0.0489,  0.0991,  0.0817, -0.0377, -0.0506,  0.1137, -0.0124, -0.0942,\n         0.0461, -0.0436,  0.1321, -0.0041, -0.0255,  0.0728, -0.0132, -0.1105,\n         0.0418, -0.1164,  0.0251, -0.0874,  0.1049,  0.0154, -0.0648, -0.0718,\n        -0.0535, -0.1072, -0.0741,  0.0565,  0.0352,  0.0714,  0.1019, -0.1221,\n         0.0127,  0.0870, -0.0848,  0.0360,  0.0743,  0.1070, -0.0809, -0.1071,\n         0.0787, -0.0594, -0.0457, -0.0698, -0.0392, -0.0091,  0.0431,  0.0669,\n        -0.0284, -0.0052, -0.0511, -0.1266,  0.0380,  0.0105, -0.1312, -0.1305,\n         0.0148,  0.0509, -0.0040, -0.0908,  0.0537, -0.0398, -0.0254, -0.0087,\n         0.0910,  0.0839, -0.1050, -0.0278, -0.0350,  0.0613, -0.0235, -0.0881,\n         0.0865, -0.0817,  0.0894, -0.0344, -0.0739, -0.0220, -0.0981,  0.0331,\n         0.0600,  0.0507,  0.0641, -0.0005,  0.0648, -0.1529,  0.0294, -0.1004,\n         0.0138, -0.1040,  0.0601,  0.0738,  0.0281,  0.1007, -0.0254,  0.0625,\n         0.1247,  0.0939, -0.0815, -0.0355,  0.0977, -0.1048,  0.0958,  0.0123,\n         0.0239, -0.0948, -0.0955, -0.0427,  0.0747,  0.0352, -0.0334, -0.0286,\n        -0.0501,  0.1043, -0.0708,  0.0884,  0.0013,  0.0060, -0.1034,  0.0417,\n        -0.0080, -0.0895,  0.0511,  0.0841, -0.0127, -0.1251, -0.0944, -0.0926,\n        -0.0452,  0.0266,  0.0710,  0.0282, -0.0366,  0.1048, -0.0840,  0.0708,\n        -0.0194,  0.0427,  0.0421,  0.0232,  0.0384,  0.0773, -0.0636, -0.1348,\n        -0.0537,  0.0627, -0.0659,  0.0978, -0.1123, -0.0591, -0.0497, -0.0687,\n        -0.0211, -0.1177, -0.0858, -0.0498, -0.0395, -0.0389,  0.1268, -0.1167,\n        -0.0827,  0.0212,  0.0565, -0.0696, -0.0658,  0.1138,  0.0448, -0.1167,\n         0.0134,  0.0296,  0.0290, -0.0696,  0.0705,  0.0859, -0.1332,  0.1421]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[-0.0416,  0.0081, -0.0471,  ..., -0.0116,  0.0138, -0.0023],\n        [-0.0342,  0.0336, -0.0383,  ..., -0.0004, -0.0140, -0.0208],\n        [ 0.0094, -0.0256, -0.0216,  ..., -0.0014, -0.0095,  0.0323],\n        ...,\n        [ 0.0337, -0.0252,  0.0476,  ...,  0.0269,  0.0005, -0.0254],\n        [ 0.0119, -0.0249,  0.0062,  ..., -0.0225,  0.0245,  0.0295],\n        [ 0.0443,  0.0161, -0.0282,  ...,  0.0078, -0.0160,  0.0132]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0110,  0.0248,  0.0303,  0.0071,  0.0298, -0.0062, -0.0440, -0.0215,\n        -0.0139,  0.0279,  0.0023, -0.0092, -0.0428,  0.0174, -0.0158, -0.0351,\n         0.0578, -0.0127, -0.0467, -0.0342, -0.0319, -0.0417,  0.0111, -0.0226,\n        -0.0305,  0.0311,  0.0060, -0.0363, -0.0102, -0.0244,  0.0118, -0.0264,\n        -0.0245,  0.0266,  0.0270,  0.0575, -0.0178,  0.0026, -0.0334,  0.0252,\n        -0.0160,  0.0463, -0.0333,  0.0302,  0.0111,  0.0155,  0.0574,  0.0255,\n        -0.0408, -0.0410,  0.0402,  0.0286,  0.0227,  0.0189,  0.0137, -0.0504,\n         0.0048,  0.0033,  0.0343,  0.0195, -0.0096,  0.0425,  0.0090,  0.0395]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.1038,  0.1191, -0.0514,  ..., -0.0309,  0.0552, -0.0169],\n        [ 0.0388, -0.1021,  0.0907,  ...,  0.1081,  0.0510, -0.0211],\n        [ 0.0765, -0.1078,  0.0652,  ..., -0.0564, -0.0068, -0.0773],\n        ...,\n        [ 0.0151,  0.0403, -0.0043,  ...,  0.0499,  0.1053,  0.0555],\n        [ 0.0682,  0.0018, -0.0380,  ...,  0.0047,  0.0923,  0.0118],\n        [-0.0924, -0.1193, -0.0202,  ...,  0.0476,  0.1172,  0.0024]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0719,  0.0435,  0.1006,  0.1101,  0.0164,  0.0071,  0.0815,  0.0461,\n         0.0628, -0.0900,  0.0449, -0.1178,  0.1205,  0.0784,  0.0156,  0.0581,\n        -0.0579,  0.0244,  0.0787, -0.0475, -0.0440, -0.0555, -0.1197,  0.0173,\n         0.0019,  0.0526, -0.0962, -0.0861, -0.0515, -0.0067, -0.1214, -0.1017,\n         0.0586,  0.1215, -0.0311, -0.0489,  0.0136,  0.0617, -0.0688, -0.0635,\n        -0.0850,  0.0893,  0.0137,  0.0921, -0.0849,  0.0165, -0.0381, -0.0315,\n        -0.0321, -0.0334, -0.0935, -0.0900,  0.0591, -0.1196,  0.1119,  0.0913,\n        -0.1039, -0.1243, -0.0536, -0.1209, -0.0803,  0.1005,  0.0951,  0.1245]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0974,  0.1151,  0.0976,  ...,  0.1224,  0.0041, -0.1076],\n        [ 0.1032, -0.0141,  0.1151,  ...,  0.0876,  0.0076, -0.0541],\n        [ 0.0067, -0.0825,  0.0349,  ...,  0.1243, -0.0359,  0.1196],\n        ...,\n        [ 0.0663,  0.0538,  0.0807,  ...,  0.0382, -0.0558, -0.1114],\n        [-0.0350,  0.1133,  0.0544,  ..., -0.0886, -0.0346, -0.0547],\n        [ 0.0010, -0.0708,  0.0124,  ...,  0.0224, -0.0921,  0.0909]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0170, -0.1190, -0.0163,  0.0180,  0.0892,  0.0154, -0.0432,  0.0846,\n        -0.0632,  0.1190,  0.0324, -0.1167, -0.0533, -0.0249, -0.0842,  0.0072,\n        -0.0665, -0.0642, -0.0509, -0.0306, -0.0569, -0.0734,  0.0363, -0.1180,\n        -0.0476, -0.0459,  0.0091, -0.0347,  0.0326, -0.0486,  0.1146,  0.0865]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-8.9725e-03, -5.6232e-02,  5.2653e-02, -1.0070e-01,  8.0529e-02,\n         -1.2664e-01,  4.5819e-02,  6.7861e-02,  1.0253e-01,  8.7408e-02,\n         -8.5727e-02,  4.1961e-02, -7.0783e-02, -1.2807e-02, -8.5416e-02,\n         -5.6530e-02, -2.2912e-02, -1.1165e-01,  1.5820e-01,  1.1725e-01,\n         -1.2391e-01, -1.5837e-01,  1.5850e-01, -9.2231e-02,  3.6164e-02,\n         -1.6964e-02, -1.4230e-01,  5.0439e-02,  1.7090e-04, -9.7547e-03,\n         -1.2355e-02, -3.5148e-02],\n        [ 2.8916e-02,  1.5201e-01,  1.6005e-01, -1.4041e-01,  1.1725e-01,\n          6.2444e-02, -8.5904e-02, -2.4250e-02,  9.0298e-02,  8.4217e-02,\n          1.7155e-01, -6.6788e-02,  4.1148e-02, -2.5535e-02, -1.1825e-01,\n          5.1646e-02, -1.1305e-01, -3.8224e-02, -1.7274e-01,  1.6546e-01,\n         -1.8081e-02,  6.2844e-02, -1.7437e-02, -6.8348e-02, -2.0858e-02,\n         -2.3944e-03, -1.6186e-01, -1.7271e-01,  1.3139e-01,  1.2958e-01,\n          1.6581e-01,  4.1241e-02]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([ 0.0736, -0.0948]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[-0.0923,  0.0482, -0.1566,  ...,  0.1353,  0.1201,  0.0295],\n        [ 0.0562,  0.1124,  0.0566,  ..., -0.1081,  0.1390,  0.1150],\n        [-0.1194, -0.1102,  0.1308,  ..., -0.0831, -0.1343,  0.1413],\n        ...,\n        [ 0.0566,  0.1062,  0.1074,  ..., -0.0533, -0.1189, -0.0092],\n        [-0.1369,  0.1021,  0.0770,  ...,  0.1645,  0.1244,  0.1437],\n        [ 0.1295,  0.0061,  0.0345,  ...,  0.0207,  0.0474,  0.0327]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([-6.5733e-03,  7.3315e-03, -1.4707e-02,  1.1457e-02,  6.1202e-03,\n         9.3523e-03,  1.4175e-02,  3.8067e-03,  6.1678e-03,  5.2377e-03,\n         1.2892e-02, -1.9642e-02, -1.0191e-02, -1.8712e-02, -2.3733e-03,\n        -5.2062e-03,  1.6054e-02,  9.9366e-03, -9.1466e-03, -6.0985e-03,\n         1.1368e-03, -1.7087e-02,  3.6428e-03,  1.3071e-02,  5.8708e-03,\n        -1.2064e-02,  3.7243e-03,  2.6175e-02,  9.7074e-03,  9.8085e-04,\n        -1.2875e-02,  8.6484e-03, -1.0571e-03, -7.3945e-03,  9.6732e-05,\n        -1.7282e-02, -1.5707e-02, -7.1973e-03,  3.6793e-03,  2.3594e-03,\n        -5.2926e-03, -1.3794e-02,  1.8214e-04,  4.5169e-03,  4.0636e-03,\n         2.8058e-03,  1.0301e-02, -1.8831e-03,  3.5926e-03,  1.9258e-02,\n        -1.0417e-02, -6.5917e-03,  6.6405e-03, -7.5677e-03,  4.9784e-03,\n        -1.0921e-02, -9.6756e-03, -8.3003e-03, -1.1722e-03,  1.8511e-02,\n         3.4050e-03, -5.0545e-03,  5.4868e-03,  4.3408e-03,  2.7145e-04,\n        -9.9331e-05, -1.6437e-04, -9.7175e-05,  1.6662e-04, -1.3174e-04,\n        -3.9741e-04, -3.8747e-05, -4.5239e-05, -8.1809e-05, -7.9783e-06,\n        -1.0540e-04, -1.2866e-04,  2.9003e-04,  1.8962e-04,  9.2106e-05,\n         3.0470e-05, -4.5787e-05,  1.8095e-04, -1.5598e-04, -2.0809e-06,\n         4.5147e-04,  3.1017e-05,  4.2814e-05, -1.5154e-04, -5.4881e-05,\n        -1.2641e-06,  3.0106e-05,  2.2063e-04,  5.7777e-05,  2.6358e-05,\n         2.3753e-05,  1.8177e-04,  5.4433e-05,  7.3739e-06, -2.4811e-04,\n        -9.0937e-05, -2.3698e-05, -2.4196e-04,  1.2629e-04,  3.7326e-05,\n         1.6489e-04, -1.0853e-04, -3.6226e-04, -2.2350e-04, -2.3472e-04,\n        -3.1234e-04,  1.1883e-04, -5.5393e-04,  8.8497e-05, -3.5697e-05,\n         5.0167e-04,  3.8532e-05,  5.1305e-04, -2.0705e-04,  1.7350e-04,\n        -1.3671e-04, -3.0985e-05, -1.3286e-05,  3.4803e-04, -5.4732e-04,\n         6.1168e-05, -1.6078e-04, -1.1954e-04, -1.7730e-03, -9.3674e-04,\n         9.2501e-04, -9.4761e-04, -2.2694e-03,  5.1635e-04, -1.3560e-03,\n        -8.9542e-04,  1.0697e-03, -4.9726e-04,  2.3384e-05, -1.4205e-03,\n        -8.7262e-04, -1.3634e-03,  1.0656e-03, -3.3237e-03, -1.4441e-04,\n         6.0201e-04, -1.2595e-03,  8.5007e-05, -2.3061e-04,  1.4608e-03,\n        -1.9165e-03, -3.8681e-04,  1.0286e-03,  8.9770e-04, -1.0937e-03,\n        -1.9365e-03,  6.9936e-04,  2.8325e-03, -1.0090e-03, -1.3966e-04,\n        -1.4688e-04,  1.8111e-04,  1.0669e-03, -7.9638e-05, -7.2004e-04,\n         1.6811e-03,  9.4748e-04, -1.0703e-03,  3.0346e-03,  2.0971e-03,\n         7.0642e-04,  1.1046e-03,  8.3996e-05,  1.7482e-03,  6.4254e-04,\n         2.4049e-03, -5.6716e-04,  2.2812e-03,  5.1605e-04, -1.4763e-04,\n         7.5019e-04,  1.9587e-03,  4.9137e-04,  1.0693e-03, -1.2591e-03,\n         6.2575e-04,  4.7323e-04,  1.6439e-03, -1.0533e-04,  1.2992e-04,\n         2.3770e-03,  8.1219e-04]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1032,  0.0821,  0.0771,  ...,  0.0560, -0.0438,  0.1301],\n        [ 0.0023, -0.0143,  0.1124,  ...,  0.0722,  0.0793, -0.0326],\n        [ 0.0349, -0.1261, -0.0152,  ...,  0.0728, -0.0861, -0.0734],\n        ...,\n        [-0.0898, -0.0845,  0.1184,  ..., -0.0383,  0.0951,  0.0632],\n        [ 0.0738, -0.0868,  0.0544,  ...,  0.1040,  0.0266, -0.0476],\n        [-0.0536,  0.1157,  0.0739,  ..., -0.0523, -0.0002,  0.0508]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([ 1.6116e-03,  2.1171e-03, -1.5696e-03, -1.9218e-03,  2.1855e-03,\n         5.2195e-04,  1.1318e-03, -1.0206e-03,  3.1140e-04, -9.3238e-05,\n        -8.0404e-04,  6.3795e-05, -2.6234e-04, -2.1786e-04, -3.2790e-04,\n         1.3873e-04,  1.1263e-03,  2.5292e-04, -1.0533e-03, -1.8160e-03,\n        -8.0762e-04,  3.5985e-04, -5.5830e-04, -5.4909e-04,  1.5298e-03,\n        -6.7638e-05,  1.0890e-04,  7.3831e-04,  1.4445e-03, -3.1870e-04,\n         7.8791e-04, -7.7567e-04,  5.0582e-05, -1.1808e-03, -1.8253e-03,\n         2.4025e-03, -1.6886e-04, -6.7533e-04,  1.8650e-04,  2.2186e-03,\n        -1.6539e-04,  1.7571e-04,  1.3755e-03, -2.3425e-03,  4.2877e-04,\n         1.5891e-04, -1.1410e-03,  1.1426e-03,  1.8965e-05, -2.4361e-04,\n        -2.2607e-04, -3.4061e-04, -1.9355e-03,  5.9588e-04, -2.6439e-04,\n         2.8423e-04,  3.0993e-04,  4.7882e-04, -1.5773e-03, -1.4080e-03,\n         8.5987e-05,  1.3822e-03,  2.9498e-04, -1.5887e-03]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=94156, training_loss=np.float64(0.0467680029778017), validation_accuracy=np.float64(0.9311111145549352), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760177152.3799605, model_hash='8e62c4ac4ff47182010af5fe245da68b166a9809b546877f3f2bd2933ce15d8a', ipfs_cid=None, blockchain_tx_hash=None)",
        "ClientUpdate(client_id='client_3', model_parameters={'meta_learner.transductive_net.feature_extractors.0.0.weight': tensor([[ 0.0763, -0.0925, -0.0928,  ..., -0.0083, -0.0481,  0.0985],\n        [-0.0954, -0.0170,  0.0618,  ...,  0.0666,  0.0353, -0.0179],\n        [ 0.0650, -0.0946,  0.1318,  ..., -0.0208, -0.1339, -0.0405],\n        ...,\n        [-0.1214, -0.0013, -0.0641,  ...,  0.0426, -0.0006, -0.0387],\n        [-0.1149, -0.0992,  0.0535,  ...,  0.0875,  0.1334, -0.0469],\n        [ 0.0538,  0.1098, -0.0363,  ..., -0.0058,  0.0689,  0.0735]]), 'meta_learner.transductive_net.feature_extractors.0.0.bias': tensor([-0.0344, -0.0874,  0.0165,  0.1119,  0.1026,  0.1220,  0.0527,  0.0347,\n         0.0624,  0.0113, -0.0608, -0.1357,  0.0110, -0.0183,  0.0701,  0.0245,\n        -0.1137,  0.0139,  0.0382,  0.0576,  0.0028, -0.0296, -0.0551,  0.0157,\n        -0.0556,  0.0316,  0.0806,  0.0693,  0.0749, -0.0626, -0.1326, -0.0988,\n        -0.0893,  0.0595,  0.1339,  0.0059, -0.0180, -0.0923,  0.0476, -0.0291,\n        -0.0487, -0.0363, -0.0126,  0.0449, -0.0247, -0.0850, -0.0814,  0.1267,\n        -0.0250, -0.1209, -0.0179,  0.0680,  0.0393, -0.0907,  0.0620, -0.0584,\n         0.0422,  0.0502, -0.0155,  0.0468,  0.0261,  0.0162,  0.0330, -0.0005,\n        -0.1334, -0.0632,  0.1118, -0.0717, -0.0636,  0.0279, -0.0847, -0.0381,\n        -0.0840, -0.0520, -0.1160,  0.0064,  0.0873,  0.0212, -0.0126, -0.0259,\n        -0.0356,  0.1210, -0.0954, -0.0609,  0.1040, -0.0380,  0.0603, -0.0930,\n         0.0613, -0.0565, -0.0085, -0.1334,  0.0770, -0.1273,  0.0311, -0.1049,\n        -0.0099,  0.1340,  0.1086,  0.0616, -0.0559, -0.0530,  0.0163,  0.0207,\n        -0.0996, -0.0943,  0.1431, -0.0229, -0.0468, -0.0091,  0.0999, -0.0855,\n         0.0859, -0.1222, -0.0610, -0.0519, -0.1299, -0.0890, -0.0158, -0.0749,\n         0.0762,  0.0719,  0.1265,  0.0926, -0.0053,  0.0248, -0.0730,  0.0280]), 'meta_learner.transductive_net.feature_extractors.1.0.weight': tensor([[ 0.1301, -0.0534, -0.0074,  ..., -0.0419, -0.0452, -0.0382],\n        [ 0.0428, -0.1060,  0.1148,  ..., -0.0488,  0.0523, -0.0923],\n        [ 0.0496, -0.0174, -0.1073,  ..., -0.0502, -0.0798, -0.0999],\n        ...,\n        [-0.1069,  0.0451,  0.0790,  ..., -0.1163, -0.0880, -0.1195],\n        [-0.1258,  0.0748,  0.0908,  ...,  0.0742, -0.0228,  0.0193],\n        [-0.0210,  0.0785, -0.0518,  ...,  0.1257, -0.1191,  0.0026]]), 'meta_learner.transductive_net.feature_extractors.1.0.bias': tensor([ 0.1033, -0.0334, -0.1226, -0.0755, -0.0031, -0.0223,  0.0935,  0.0906,\n        -0.1041, -0.0614, -0.0105, -0.1063, -0.1058,  0.0678, -0.0442,  0.1156,\n         0.0637, -0.0637,  0.0206,  0.0337, -0.1032, -0.0904,  0.1035,  0.0074,\n        -0.1110,  0.0735, -0.1265, -0.0204,  0.0254, -0.0973,  0.0634,  0.0507,\n         0.0791,  0.0359, -0.0361,  0.0622, -0.0950,  0.0087,  0.0658,  0.0504,\n         0.0793, -0.1171, -0.1261, -0.0649,  0.0608,  0.0340, -0.0930, -0.0493,\n         0.0670,  0.0388,  0.0993, -0.1040, -0.1133, -0.0208, -0.0022, -0.1068,\n         0.0524,  0.0277,  0.0923, -0.1078, -0.1141, -0.0359,  0.0699,  0.0507]), 'meta_learner.transductive_net.feature_extractors.2.0.weight': tensor([[-0.0156,  0.1062, -0.0719,  ...,  0.0376, -0.0556, -0.0183],\n        [ 0.0615, -0.1214,  0.0181,  ...,  0.0568,  0.0471, -0.1268],\n        [ 0.1242, -0.0808, -0.1228,  ...,  0.0096, -0.0460,  0.1183],\n        ...,\n        [-0.0698, -0.0900, -0.0268,  ...,  0.0147, -0.1032, -0.0043],\n        [ 0.0470, -0.0097,  0.0647,  ..., -0.0675,  0.1317, -0.0481],\n        [-0.1266,  0.0980, -0.0851,  ...,  0.0549, -0.0283, -0.0953]]), 'meta_learner.transductive_net.feature_extractors.2.0.bias': tensor([ 0.0829, -0.0715, -0.0583, -0.1367, -0.1122,  0.0470,  0.0893, -0.0610,\n         0.0078,  0.1194, -0.0357,  0.0550, -0.1520, -0.1055, -0.1236, -0.0796,\n         0.0189, -0.0018, -0.1270, -0.0813,  0.0152,  0.1156, -0.1201, -0.1408,\n         0.0237,  0.0825, -0.0410,  0.0959,  0.0369,  0.0356,  0.0768,  0.1306,\n         0.0493,  0.0014, -0.1121, -0.1298,  0.0296, -0.0211, -0.0427, -0.0027,\n        -0.1016,  0.1253,  0.0968,  0.1410, -0.0037, -0.1067, -0.0170,  0.0862,\n         0.0461, -0.1172,  0.0999, -0.0335,  0.0622, -0.1080,  0.0841,  0.0537,\n         0.0617,  0.0571, -0.0891, -0.0418, -0.0126, -0.1243,  0.0405, -0.0272,\n         0.0581, -0.0230, -0.0984,  0.0179, -0.0325,  0.0810,  0.0303, -0.0367,\n         0.0875,  0.0767,  0.0586,  0.0067, -0.0036, -0.0610, -0.1327,  0.0002,\n         0.0519,  0.1311,  0.0796, -0.0266, -0.0520,  0.1052, -0.0381, -0.1125,\n         0.0418, -0.0612,  0.1210,  0.0070, -0.0549,  0.0588, -0.0271, -0.1128,\n         0.0445, -0.1216,  0.0332, -0.0975,  0.1129, -0.0013, -0.0598, -0.0892,\n        -0.0269, -0.1077, -0.0827,  0.0604,  0.0251,  0.0558,  0.1014, -0.1177,\n         0.0207,  0.1088, -0.0927,  0.0365,  0.0932,  0.1008, -0.0829, -0.1183,\n         0.1024, -0.0478, -0.0387, -0.0700, -0.0204,  0.0023,  0.0156,  0.0703,\n        -0.0453,  0.0016, -0.0485, -0.1348,  0.0381, -0.0051, -0.1269, -0.1345,\n         0.0101,  0.0281,  0.0065, -0.1021,  0.0541, -0.0438, -0.0283, -0.0377,\n         0.0730,  0.0625, -0.0841, -0.0017, -0.0297,  0.0632, -0.0142, -0.0757,\n         0.0837, -0.0521,  0.1239, -0.0283, -0.0594, -0.0170, -0.1161,  0.0273,\n         0.0353,  0.0287,  0.0513, -0.0018,  0.0454, -0.1405,  0.0032, -0.0996,\n         0.0096, -0.1076,  0.0339,  0.0867,  0.0221,  0.0971, -0.0028,  0.0674,\n         0.1094,  0.1064, -0.0928, -0.0274,  0.0835, -0.1064,  0.1047,  0.0082,\n         0.0117, -0.0716, -0.1088, -0.0690,  0.0411, -0.0074, -0.0340, -0.0189,\n        -0.0496,  0.0996, -0.0665,  0.0891,  0.0234,  0.0130, -0.1157,  0.0666,\n        -0.0069, -0.1048,  0.0509,  0.0802, -0.0287, -0.1158, -0.0869, -0.1025,\n        -0.0233,  0.0175,  0.0554,  0.0425, -0.0518,  0.1041, -0.0721,  0.0983,\n        -0.0122,  0.0549,  0.0572,  0.0220,  0.0235,  0.0915, -0.0483, -0.1332,\n        -0.0727,  0.0700, -0.0602,  0.1093, -0.1293, -0.0482, -0.0308, -0.0652,\n        -0.0177, -0.1000, -0.0934, -0.0234, -0.0492, -0.0171,  0.1179, -0.1091,\n        -0.0858,  0.0235,  0.0439, -0.0657, -0.0684,  0.1166,  0.0583, -0.1371,\n         0.0227,  0.0194,  0.0417, -0.0626,  0.0887,  0.0946, -0.1273,  0.1150]), 'meta_learner.transductive_net.feature_projection.0.weight': tensor([[-4.0571e-02,  8.6653e-03, -4.5661e-02,  ..., -9.6966e-03,\n          9.7105e-03,  3.8159e-05],\n        [-1.5957e-02,  4.5452e-02, -1.2498e-02,  ...,  5.7883e-03,\n         -1.1750e-02, -2.3126e-02],\n        [-2.2191e-02, -3.2422e-02, -1.7061e-02,  ...,  1.1197e-02,\n         -1.3354e-02,  3.6194e-02],\n        ...,\n        [ 4.1873e-02, -3.7046e-02,  5.5076e-02,  ...,  4.2747e-02,\n         -6.9921e-03, -1.2377e-02],\n        [ 6.4664e-03,  1.6239e-02,  1.5753e-02,  ..., -2.0398e-02,\n          2.5734e-02,  1.9690e-02],\n        [ 1.9545e-02,  1.4233e-02, -1.0040e-02,  ...,  1.1617e-02,\n         -1.2283e-02,  1.4381e-02]]), 'meta_learner.transductive_net.feature_projection.0.bias': tensor([-0.0150,  0.0420,  0.0163, -0.0114,  0.0388, -0.0046, -0.0276, -0.0088,\n        -0.0092,  0.0285,  0.0001, -0.0238, -0.0599,  0.0261, -0.0094, -0.0532,\n         0.0262, -0.0164, -0.0411, -0.0069, -0.0169, -0.0484,  0.0038, -0.0130,\n        -0.0524,  0.0352,  0.0081, -0.0354, -0.0329, -0.0208,  0.0394, -0.0208,\n        -0.0443,  0.0164,  0.0320,  0.0345, -0.0242,  0.0032, -0.0409,  0.0306,\n        -0.0149,  0.0365, -0.0242,  0.0462,  0.0079,  0.0304,  0.0475,  0.0352,\n        -0.0400, -0.0522,  0.0301,  0.0280,  0.0284,  0.0055,  0.0179, -0.0444,\n         0.0084, -0.0131,  0.0267,  0.0222, -0.0246,  0.0360,  0.0150,  0.0509]), 'meta_learner.transductive_net.classifier.0.weight': tensor([[-0.1038,  0.1191, -0.0514,  ..., -0.0309,  0.0552, -0.0169],\n        [ 0.0388, -0.1021,  0.0907,  ...,  0.1081,  0.0510, -0.0211],\n        [ 0.0765, -0.1078,  0.0652,  ..., -0.0564, -0.0068, -0.0773],\n        ...,\n        [ 0.0151,  0.0403, -0.0043,  ...,  0.0499,  0.1053,  0.0555],\n        [ 0.0682,  0.0018, -0.0380,  ...,  0.0047,  0.0923,  0.0118],\n        [-0.0924, -0.1193, -0.0202,  ...,  0.0476,  0.1172,  0.0024]]), 'meta_learner.transductive_net.classifier.0.bias': tensor([ 0.0719,  0.0435,  0.1006,  0.1101,  0.0164,  0.0071,  0.0815,  0.0461,\n         0.0628, -0.0900,  0.0449, -0.1178,  0.1205,  0.0784,  0.0156,  0.0581,\n        -0.0579,  0.0244,  0.0787, -0.0475, -0.0440, -0.0555, -0.1197,  0.0173,\n         0.0019,  0.0526, -0.0962, -0.0861, -0.0515, -0.0067, -0.1214, -0.1017,\n         0.0586,  0.1215, -0.0311, -0.0489,  0.0136,  0.0617, -0.0688, -0.0635,\n        -0.0850,  0.0893,  0.0137,  0.0921, -0.0849,  0.0165, -0.0381, -0.0315,\n        -0.0321, -0.0334, -0.0935, -0.0900,  0.0591, -0.1196,  0.1119,  0.0913,\n        -0.1039, -0.1243, -0.0536, -0.1209, -0.0803,  0.1005,  0.0951,  0.1245]), 'meta_learner.transductive_net.classifier.3.weight': tensor([[ 0.0974,  0.1151,  0.0976,  ...,  0.1224,  0.0041, -0.1076],\n        [ 0.1032, -0.0141,  0.1151,  ...,  0.0876,  0.0076, -0.0541],\n        [ 0.0067, -0.0825,  0.0349,  ...,  0.1243, -0.0359,  0.1196],\n        ...,\n        [ 0.0663,  0.0538,  0.0807,  ...,  0.0382, -0.0558, -0.1114],\n        [-0.0350,  0.1133,  0.0544,  ..., -0.0886, -0.0346, -0.0547],\n        [ 0.0010, -0.0708,  0.0124,  ...,  0.0224, -0.0921,  0.0909]]), 'meta_learner.transductive_net.classifier.3.bias': tensor([ 0.0170, -0.1190, -0.0163,  0.0180,  0.0892,  0.0154, -0.0432,  0.0846,\n        -0.0632,  0.1190,  0.0324, -0.1167, -0.0533, -0.0249, -0.0842,  0.0072,\n        -0.0665, -0.0642, -0.0509, -0.0306, -0.0569, -0.0734,  0.0363, -0.1180,\n        -0.0476, -0.0459,  0.0091, -0.0347,  0.0326, -0.0486,  0.1146,  0.0865]), 'meta_learner.transductive_net.classifier.6.weight': tensor([[-8.9725e-03, -5.6232e-02,  5.2653e-02, -1.0070e-01,  8.0529e-02,\n         -1.2664e-01,  4.5819e-02,  6.7861e-02,  1.0253e-01,  8.7408e-02,\n         -8.5727e-02,  4.1961e-02, -7.0783e-02, -1.2807e-02, -8.5416e-02,\n         -5.6530e-02, -2.2912e-02, -1.1165e-01,  1.5820e-01,  1.1725e-01,\n         -1.2391e-01, -1.5837e-01,  1.5850e-01, -9.2231e-02,  3.6164e-02,\n         -1.6964e-02, -1.4230e-01,  5.0439e-02,  1.7090e-04, -9.7547e-03,\n         -1.2355e-02, -3.5148e-02],\n        [ 2.8916e-02,  1.5201e-01,  1.6005e-01, -1.4041e-01,  1.1725e-01,\n          6.2444e-02, -8.5904e-02, -2.4250e-02,  9.0298e-02,  8.4217e-02,\n          1.7155e-01, -6.6788e-02,  4.1148e-02, -2.5535e-02, -1.1825e-01,\n          5.1646e-02, -1.1305e-01, -3.8224e-02, -1.7274e-01,  1.6546e-01,\n         -1.8081e-02,  6.2844e-02, -1.7437e-02, -6.8348e-02, -2.0858e-02,\n         -2.3944e-03, -1.6186e-01, -1.7271e-01,  1.3139e-01,  1.2958e-01,\n          1.6581e-01,  4.1241e-02]]), 'meta_learner.transductive_net.classifier.6.bias': tensor([ 0.0736, -0.0948]), 'meta_learner.transductive_net.self_attention.in_proj_weight': tensor([[-0.0981,  0.0375, -0.1574,  ...,  0.1116,  0.1262,  0.0160],\n        [ 0.0720,  0.1340,  0.0525,  ..., -0.1014,  0.1491,  0.1225],\n        [-0.1292, -0.1446,  0.1054,  ..., -0.0777, -0.1303,  0.1538],\n        ...,\n        [ 0.0529,  0.1400,  0.1135,  ..., -0.0688, -0.1257, -0.0045],\n        [-0.1421,  0.0976,  0.0599,  ...,  0.1672,  0.1238,  0.1435],\n        [ 0.1305,  0.0221,  0.0325,  ...,  0.0094,  0.0249,  0.0283]]), 'meta_learner.transductive_net.self_attention.in_proj_bias': tensor([ 1.9804e-02, -1.4769e-02,  1.8101e-02, -3.9346e-04, -1.4016e-02,\n         2.7904e-03,  4.3895e-03,  1.7691e-03, -1.6056e-03,  2.3958e-03,\n         1.3083e-02,  7.5561e-03,  4.8914e-03,  5.8084e-04, -7.6219e-03,\n        -6.1298e-03, -4.3996e-04,  6.5411e-03, -1.0363e-02,  8.1008e-03,\n         7.3570e-03,  6.4278e-03,  1.9272e-03,  3.8294e-03, -1.4812e-02,\n         1.9433e-03,  4.1933e-03,  2.6632e-03,  1.4310e-03,  7.0645e-03,\n        -1.0722e-02, -1.2300e-02, -6.3422e-03,  5.7245e-04, -1.3487e-02,\n        -7.7937e-04,  3.1068e-04,  5.8485e-03,  3.8117e-03,  2.9160e-03,\n        -1.5824e-03, -1.2081e-02,  5.4735e-03, -3.7629e-03,  1.6634e-02,\n        -1.5124e-02, -2.0163e-02,  9.5109e-04, -8.0989e-03,  1.4404e-02,\n        -4.1047e-03,  7.8839e-03,  8.2263e-03, -1.8864e-02,  4.5538e-04,\n        -2.2179e-02, -1.3015e-02,  1.2000e-03, -6.5208e-03, -1.1689e-02,\n        -1.2894e-02, -1.4733e-02,  1.6130e-02,  1.5824e-02,  1.1570e-06,\n        -2.1729e-04,  3.9821e-04,  1.6392e-04,  6.6656e-05,  1.0046e-04,\n        -1.5027e-04,  4.7248e-04,  3.6928e-04, -4.5480e-04,  3.7804e-04,\n         1.1054e-04,  7.0683e-05,  8.3422e-05, -2.3715e-06,  5.3588e-05,\n         6.3944e-04, -5.4321e-04, -1.5082e-04,  1.6819e-04, -1.0027e-04,\n        -4.9097e-04, -1.3879e-04,  2.2080e-04,  2.2240e-04,  2.2445e-04,\n         4.4820e-04, -2.8721e-04,  3.8212e-05,  3.2827e-04, -2.7272e-04,\n         2.3548e-04,  7.1584e-06, -2.1635e-04,  2.1460e-04, -1.1351e-05,\n        -2.4873e-04,  2.4023e-04, -2.6261e-05, -1.2000e-04, -2.5025e-04,\n        -2.0156e-04,  7.5320e-05, -2.0224e-04, -2.9691e-05, -6.1179e-05,\n         2.6779e-04, -4.6301e-05, -1.0308e-04, -4.8398e-05, -7.5319e-05,\n        -5.5438e-05,  2.6287e-05, -1.2073e-04, -2.3757e-04, -8.0211e-05,\n         1.2336e-05, -1.6936e-04,  1.1609e-04, -9.1778e-05,  2.3396e-04,\n        -1.9367e-04,  2.3739e-04, -1.6339e-05,  1.2877e-03, -3.5236e-04,\n        -8.5833e-04,  9.8746e-04, -6.2673e-04,  5.9205e-05, -1.1221e-03,\n        -4.2957e-04, -9.1102e-04, -3.7371e-03,  1.5264e-03, -1.4186e-03,\n         7.9193e-04,  1.1052e-03,  8.0247e-04, -4.5905e-04,  6.2001e-04,\n         1.2759e-03, -1.0364e-03, -2.7395e-04,  9.4207e-04, -7.8668e-04,\n         6.7627e-04,  2.2042e-03, -2.6266e-04,  1.4402e-03,  1.5890e-04,\n        -6.1434e-04, -5.5647e-04,  9.1339e-04,  9.7831e-04, -5.3910e-04,\n         9.0319e-04, -3.5156e-04,  1.6661e-04, -3.1113e-06, -9.4013e-04,\n        -2.6958e-04, -6.9819e-04, -5.9516e-04,  1.0766e-03,  7.8228e-04,\n         1.2386e-03,  5.3354e-04, -6.3478e-04,  2.2744e-03,  1.7567e-03,\n         4.2735e-04, -4.3754e-04, -1.3580e-03,  1.9318e-03,  1.3281e-03,\n         5.8510e-04,  8.1552e-04,  4.8442e-03, -4.7259e-04, -3.3185e-04,\n        -4.7902e-04, -9.2756e-04, -2.7134e-04, -7.3441e-04,  5.8046e-04,\n        -3.2922e-04, -1.2680e-03]), 'meta_learner.transductive_net.self_attention.out_proj.weight': tensor([[ 0.1087,  0.0722,  0.0751,  ...,  0.0764, -0.0451,  0.1310],\n        [ 0.0006, -0.0236,  0.1250,  ...,  0.0795,  0.0606, -0.0428],\n        [ 0.0327, -0.1152, -0.0128,  ...,  0.0794, -0.0509, -0.0636],\n        ...,\n        [-0.0941, -0.0919,  0.1096,  ..., -0.0541,  0.0638,  0.0561],\n        [ 0.0679, -0.0932,  0.0387,  ...,  0.1146,  0.0241, -0.0267],\n        [-0.0516,  0.0960,  0.0544,  ..., -0.0460, -0.0241,  0.0534]]), 'meta_learner.transductive_net.self_attention.out_proj.bias': tensor([-1.8196e-03,  8.6300e-04, -2.7469e-04, -4.1501e-04, -4.3152e-04,\n         9.2387e-04,  2.2094e-03, -5.9973e-04,  2.8352e-04,  8.7102e-04,\n         3.0337e-04, -2.5277e-04, -1.2681e-03,  3.1697e-04,  3.7968e-04,\n         8.6188e-04,  3.7129e-04,  1.5214e-03, -1.5444e-03, -1.6049e-03,\n        -4.5924e-04,  6.4781e-04, -1.0692e-03, -1.7449e-03, -1.1808e-03,\n         2.2067e-03,  7.5488e-04,  8.6777e-07,  4.9335e-04,  1.1035e-06,\n        -1.8517e-03, -2.8233e-04,  6.6682e-04,  1.4294e-03,  2.9400e-04,\n         4.2268e-04,  8.3646e-05,  2.2189e-03, -1.3915e-04, -4.3860e-04,\n         1.7310e-03,  1.1591e-03, -1.6495e-03, -7.1573e-04, -1.3906e-03,\n        -2.3262e-03, -4.7672e-04,  7.6102e-04, -1.4709e-04,  1.1267e-03,\n         1.1642e-03,  1.8932e-03,  7.0225e-04, -7.1645e-04, -5.3069e-04,\n         1.4657e-04,  4.5499e-04,  5.7469e-04, -1.5346e-03,  4.2515e-04,\n        -8.9553e-04,  2.0759e-04,  1.1565e-03, -1.2792e-03]), 'meta_learner.transductive_net.layer_norm.weight': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'meta_learner.transductive_net.layer_norm.bias': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, sample_count=18768, training_loss=np.float64(0.06591666811663242), validation_accuracy=np.float64(0.9044444561004636), validation_precision=0.0, validation_recall=0.0, validation_f1_score=0.0, timestamp=1760177152.7589438, model_hash='0f3976dd1a0871fe0982020035bb58c20d9e697b0cdcc943d07c07fb4a630376', ipfs_cid=None, blockchain_tx_hash=None)"
      ],
      "validation_metrics": {
        "loss": 0.704220175743103,
        "accuracy": 0.314,
        "f1_score": 0.15007001522070015,
        "samples": 1000
      }
    }
  ],
  "evaluation_results": {
    "base_model": {
      "accuracy": 0.786,
      "precision": 0.7883064516129032,
      "recall": 0.782,
      "f1_score": 0.785996575945215,
      "mccc": 0.5720183048786388,
      "zero_day_detection_rate": 0.5,
      "optimal_threshold": "0.53419733",
      "roc_auc": 0.83874,
      "confusion_matrix": {
        "tn": 790,
        "fp": 210,
        "fn": 218,
        "tp": 782
      },
      "test_samples": 2000,
      "query_samples": 2000,
      "support_samples": 500
    },
    "ttt_model": {
      "accuracy": 0.8711111111111111,
      "precision": 0.872093023255814,
      "recall": 0.9,
      "f1_score": 0.8858267716535433,
      "mccc": 0.7384343214484436,
      "zero_day_detection_rate": 0.5555555555555556,
      "avg_confidence": "0.578123",
      "confusion_matrix": {
        "tn": 167,
        "fp": 33,
        "fn": 25,
        "tp": 225
      },
      "support_samples": 50,
      "query_samples": 450,
      "ttt_adaptation_steps": 10,
      "optimal_threshold": "0.8874027",
      "roc_auc": 0.9330799999999999,
      "roc_curve": {
        "fpr": [
          0.0,
          0.0,
          0.055,
          0.055,
          0.055,
          0.075,
          0.075,
          0.08,
          0.08,
          0.085,
          0.085,
          0.09,
          0.09,
          0.095,
          0.095,
          0.1,
          0.1,
          0.105,
          0.105,
          0.11,
          0.11,
          0.12,
          0.12,
          0.125,
          0.125,
          0.13,
          0.13,
          0.14,
          0.14,
          0.15,
          0.15,
          0.165,
          0.165,
          0.17,
          0.17,
          0.18,
          0.18,
          0.185,
          0.185,
          0.19,
          0.19,
          0.195,
          0.195,
          0.21,
          0.21,
          0.24,
          0.24,
          0.245,
          0.245,
          0.25,
          0.25,
          0.26,
          0.26,
          0.3,
          0.3,
          0.32,
          0.32,
          0.37,
          0.37,
          0.39,
          0.39,
          0.415,
          0.415,
          0.465,
          0.465,
          0.53,
          0.57,
          0.575,
          0.59,
          0.6,
          0.615,
          0.695,
          0.755,
          0.81,
          0.855,
          0.9,
          0.925,
          0.955,
          0.97,
          0.99,
          1.0
        ],
        "tpr": [
          0.0,
          0.008,
          0.708,
          0.716,
          0.728,
          0.728,
          0.736,
          0.736,
          0.772,
          0.772,
          0.78,
          0.78,
          0.8,
          0.8,
          0.804,
          0.804,
          0.812,
          0.812,
          0.832,
          0.832,
          0.864,
          0.864,
          0.868,
          0.868,
          0.872,
          0.872,
          0.876,
          0.876,
          0.88,
          0.88,
          0.884,
          0.884,
          0.9,
          0.9,
          0.904,
          0.904,
          0.908,
          0.908,
          0.912,
          0.912,
          0.924,
          0.924,
          0.928,
          0.928,
          0.932,
          0.932,
          0.936,
          0.936,
          0.952,
          0.952,
          0.968,
          0.968,
          0.972,
          0.972,
          0.976,
          0.976,
          0.98,
          0.98,
          0.984,
          0.984,
          0.988,
          0.988,
          0.992,
          0.992,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          0.996,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "thresholds": [
          Infinity,
          0.9998524188995361,
          0.9998522996902466,
          0.999852180480957,
          0.9998303651809692,
          0.9998005032539368,
          0.9997879862785339,
          0.9997727274894714,
          0.9997616410255432,
          0.9997560381889343,
          0.9997536540031433,
          0.9997504353523254,
          0.9997385144233704,
          0.9997254014015198,
          0.999721348285675,
          0.9997105002403259,
          0.9997056126594543,
          0.9997046589851379,
          0.9996337890625,
          0.9996182918548584,
          0.9991292357444763,
          0.9988942742347717,
          0.9986807703971863,
          0.9985779523849487,
          0.9985315799713135,
          0.9985032081604004,
          0.9981854557991028,
          0.9972565770149231,
          0.9969923496246338,
          0.98853999376297,
          0.9797266721725464,
          0.9576120972633362,
          0.8874027132987976,
          0.6733617186546326,
          0.5183960795402527,
          0.4279254376888275,
          0.23565085232257843,
          0.19101013243198395,
          0.019023913890123367,
          0.01834023743867874,
          0.013126828707754612,
          0.01067435834556818,
          0.007814306765794754,
          0.0031394094694405794,
          0.001897008391097188,
          0.00045381340896710753,
          0.00041111104656010866,
          0.00039603965706191957,
          0.00031934116850607097,
          0.00030943885212764144,
          0.00029369216645136476,
          0.0002749677805695683,
          0.00026745349168777466,
          0.00023402734950650483,
          0.00023397804761771113,
          0.00022587954299524426,
          0.00022579167853109539,
          0.00021184860088396817,
          0.0002096055104630068,
          0.00020669662626460195,
          0.00020501823746599257,
          0.0001996864884858951,
          0.00019960214558523148,
          0.00018869343330152333,
          0.00018258235650137067,
          0.00014763687795493752,
          0.00014763603394385427,
          0.000147635888424702,
          0.0001476357429055497,
          0.00014763561193831265,
          0.00014763546641916037,
          0.00014763518993277103,
          0.00014763504441361874,
          0.00014763489889446646,
          0.00014763475337531418,
          0.00014763462240807712,
          0.00014763447688892484,
          0.00014763434592168778,
          0.0001476342004025355,
          0.00014763406943529844,
          0.00014763392391614616
        ]
      }
    },
    "base_model_kfold": {
      "accuracy_mean": 0.5,
      "accuracy_std": 0.0,
      "precision_mean": 0.5,
      "precision_std": 0.0,
      "recall_mean": 0.5,
      "recall_std": 0.0,
      "macro_f1_mean": 0.3333333333333333,
      "macro_f1_std": 0.0,
      "mcc_mean": 0.0,
      "mcc_std": 0.0,
      "confusion_matrix": [
        [
          1363,
          0
        ],
        [
          1363,
          0
        ]
      ],
      "roc_curve": {
        "fpr": [
          0.0,
          0.0,
          0.0,
          0.0007336757153338225,
          0.0007336757153338225,
          0.001467351430667645,
          0.001467351430667645,
          0.0022010271460014674,
          0.0022010271460014674,
          0.00293470286133529,
          0.00293470286133529,
          0.003668378576669112,
          0.003668378576669112,
          0.004402054292002935,
          0.004402054292002935,
          0.005135730007336757,
          0.005135730007336757,
          0.006603081438004402,
          0.006603081438004402,
          0.008070432868672046,
          0.008070432868672046,
          0.00880410858400587,
          0.00880410858400587,
          0.011005135730007337,
          0.011005135730007337,
          0.012472487160674981,
          0.012472487160674981,
          0.013206162876008804,
          0.013206162876008804,
          0.016140865737344093,
          0.016140865737344093,
          0.016874541452677916,
          0.016874541452677916,
          0.018341892883345562,
          0.018341892883345562,
          0.019075568598679385,
          0.019075568598679385,
          0.019809244314013204,
          0.019809244314013204,
          0.020542920029347028,
          0.020542920029347028,
          0.022010271460014674,
          0.022010271460014674,
          0.02347762289068232,
          0.02347762289068232,
          0.02421129860601614,
          0.02421129860601614,
          0.024944974321349962,
          0.024944974321349962,
          0.025678650036683785,
          0.025678650036683785,
          0.02714600146735143,
          0.02714600146735143,
          0.03008070432868672,
          0.03008070432868672,
          0.03301540719002201,
          0.03301540719002201,
          0.03374908290535583,
          0.03374908290535583,
          0.034482758620689655,
          0.034482758620689655,
          0.03521643433602348,
          0.03521643433602348,
          0.03888481291269259,
          0.03888481291269259,
          0.04035216434336023,
          0.04035216434336023,
          0.04181951577402788,
          0.04181951577402788,
          0.0425531914893617,
          0.0425531914893617,
          0.04402054292002935,
          0.04402054292002935,
          0.04475421863536317,
          0.04475421863536317,
          0.04548789435069699,
          0.04548789435069699,
          0.046221570066030816,
          0.046221570066030816,
          0.04695524578136464,
          0.04695524578136464,
          0.04768892149669846,
          0.04768892149669846,
          0.04842259721203228,
          0.04842259721203228,
          0.0491562729273661,
          0.0491562729273661,
          0.049889948642699924,
          0.049889948642699924,
          0.05062362435803375,
          0.05062362435803375,
          0.05062362435803375,
          0.05062362435803375,
          0.05135730007336757,
          0.05135730007336757,
          0.052090975788701394,
          0.052090975788701394,
          0.05282465150403522,
          0.05282465150403522,
          0.05355832721936904,
          0.05355832721936904,
          0.05429200293470286,
          0.05429200293470286,
          0.055025678650036686,
          0.055025678650036686,
          0.05575935436537051,
          0.05575935436537051,
          0.05649303008070433,
          0.05649303008070433,
          0.05722670579603815,
          0.05722670579603815,
          0.05796038151137197,
          0.05796038151137197,
          0.058694057226705794,
          0.058694057226705794,
          0.05942773294203962,
          0.05942773294203962,
          0.06016140865737344,
          0.06016140865737344,
          0.06089508437270726,
          0.06089508437270726,
          0.061628760088041086,
          0.061628760088041086,
          0.06236243580337491,
          0.06236243580337491,
          0.06309611151870873,
          0.06309611151870873,
          0.06382978723404255,
          0.06382978723404255,
          0.06603081438004402,
          0.06603081438004402,
          0.06676449009537784,
          0.06676449009537784,
          0.06749816581071166,
          0.06749816581071166,
          0.06823184152604549,
          0.06823184152604549,
          0.06896551724137931,
          0.06896551724137931,
          0.06969919295671313,
          0.06969919295671313,
          0.07043286867204696,
          0.07043286867204696,
          0.07116654438738078,
          0.07116654438738078,
          0.0719002201027146,
          0.0719002201027146,
          0.07263389581804842,
          0.07263389581804842,
          0.07336757153338225,
          0.07336757153338225,
          0.07410124724871607,
          0.07410124724871607,
          0.0748349229640499,
          0.0748349229640499,
          0.07556859867938372,
          0.07556859867938372,
          0.07630227439471754,
          0.07630227439471754,
          0.07703595011005136,
          0.07703595011005136,
          0.07776962582538519,
          0.07776962582538519,
          0.07850330154071901,
          0.07850330154071901,
          0.07923697725605282,
          0.07923697725605282,
          0.08070432868672046,
          0.08070432868672046,
          0.08143800440205429,
          0.08143800440205429,
          0.08217168011738811,
          0.08217168011738811,
          0.08363903154805576,
          0.08363903154805576,
          0.08437270726338958,
          0.08437270726338958,
          0.0851063829787234,
          0.0851063829787234,
          0.08584005869405723,
          0.08584005869405723,
          0.08657373440939105,
          0.08657373440939105,
          0.08730741012472487,
          0.08730741012472487,
          0.08877476155539252,
          0.08877476155539252,
          0.08950843727072634,
          0.08950843727072634,
          0.09024211298606016,
          0.09024211298606016,
          0.09097578870139399,
          0.09097578870139399,
          0.09244314013206163,
          0.09244314013206163,
          0.09317681584739546,
          0.09317681584739546,
          0.09391049156272928,
          0.09391049156272928,
          0.09611151870873075,
          0.09611151870873075,
          0.09684519442406456,
          0.09684519442406456,
          0.09757887013939838,
          0.09757887013939838,
          0.0983125458547322,
          0.0983125458547322,
          0.09904622157006603,
          0.09904622157006603,
          0.09977989728539985,
          0.09977989728539985,
          0.10051357300073367,
          0.10051357300073367,
          0.1012472487160675,
          0.1012472487160675,
          0.10198092443140132,
          0.10198092443140132,
          0.10418195157740279,
          0.10418195157740279,
          0.10491562729273661,
          0.10491562729273661,
          0.10638297872340426,
          0.10638297872340426,
          0.10711665443873808,
          0.10711665443873808,
          0.1078503301540719,
          0.10858400586940573,
          0.10858400586940573,
          0.10931768158473955,
          0.10931768158473955,
          0.11005135730007337,
          0.11005135730007337,
          0.11298606016140866,
          0.11298606016140866,
          0.1144534115920763,
          0.1144534115920763,
          0.11518708730741012,
          0.11518708730741012,
          0.11592076302274394,
          0.11592076302274394,
          0.11665443873807776,
          0.11665443873807776,
          0.11812179016874541,
          0.11812179016874541,
          0.11885546588407923,
          0.11885546588407923,
          0.11958914159941306,
          0.11958914159941306,
          0.1210564930300807,
          0.1210564930300807,
          0.12179016874541453,
          0.12179016874541453,
          0.12252384446074835,
          0.12252384446074835,
          0.12472487160674982,
          0.12472487160674982,
          0.12545854732208364,
          0.12545854732208364,
          0.12619222303741745,
          0.12619222303741745,
          0.1276595744680851,
          0.1276595744680851,
          0.1305942773294204,
          0.1305942773294204,
          0.13646368305209097,
          0.13646368305209097,
          0.13939838591342626,
          0.13939838591342626,
          0.1401320616287601,
          0.1401320616287601,
          0.1408657373440939,
          0.1408657373440939,
          0.14159941305942772,
          0.14159941305942772,
          0.1438004402054292,
          0.1438004402054292,
          0.14526779163609685,
          0.14526779163609685,
          0.14600146735143066,
          0.14600146735143066,
          0.1467351430667645,
          0.1467351430667645,
          0.1474688187820983,
          0.1474688187820983,
          0.14820249449743214,
          0.14820249449743214,
          0.14893617021276595,
          0.14893617021276595,
          0.15260454878943508,
          0.15260454878943508,
          0.1533382245047689,
          0.1533382245047689,
          0.15407190022010273,
          0.15407190022010273,
          0.15553925165077037,
          0.15553925165077037,
          0.15627292736610418,
          0.15627292736610418,
          0.15774027879677183,
          0.15774027879677183,
          0.15847395451210564,
          0.15847395451210564,
          0.15920763022743947,
          0.15920763022743947,
          0.16140865737344093,
          0.16140865737344093,
          0.16287600880410857,
          0.16287600880410857,
          0.16581071166544387,
          0.16581071166544387,
          0.1665443873807777,
          0.1665443873807777,
          0.16801173881144535,
          0.16801173881144535,
          0.169479090242113,
          0.169479090242113,
          0.1702127659574468,
          0.1702127659574468,
          0.17094644167278064,
          0.17094644167278064,
          0.1724137931034483,
          0.1724137931034483,
          0.17388114453411593,
          0.17388114453411593,
          0.17461482024944974,
          0.17461482024944974,
          0.17534849596478358,
          0.17534849596478358,
          0.1768158473954512,
          0.1768158473954512,
          0.18048422597212033,
          0.18048422597212033,
          0.18121790168745414,
          0.18121790168745414,
          0.18195157740278797,
          0.18195157740278797,
          0.18268525311812178,
          0.18268525311812178,
          0.18341892883345562,
          0.18341892883345562,
          0.18415260454878943,
          0.18415260454878943,
          0.19148936170212766,
          0.19148936170212766,
          0.1922230374174615,
          0.1922230374174615,
          0.1936903888481291,
          0.1936903888481291,
          0.1958914159941306,
          0.1958914159941306,
          0.1988261188554659,
          0.1988261188554659,
          0.1995597945707997,
          0.1995597945707997,
          0.20029347028613353,
          0.20029347028613353,
          0.202494497432135,
          0.202494497432135,
          0.20322817314746883,
          0.20322817314746883,
          0.20542920029347028,
          0.20542920029347028,
          0.20616287600880412,
          0.20616287600880412,
          0.20763022743947177,
          0.20763022743947177,
          0.2090975788701394,
          0.2090975788701394,
          0.20983125458547322,
          0.20983125458547322,
          0.21129860601614087,
          0.21129860601614087,
          0.21203228173147468,
          0.21203228173147468,
          0.21496698459280997,
          0.21496698459280997,
          0.2164343360234776,
          0.2164343360234776,
          0.21716801173881145,
          0.21716801173881145,
          0.22010271460014674,
          0.22010271460014674,
          0.22083639031548055,
          0.22083639031548055,
          0.2223037417461482,
          0.2223037417461482,
          0.22303741746148203,
          0.22303741746148203,
          0.2289068231841526,
          0.2289068231841526,
          0.22964049889948643,
          0.22964049889948643,
          0.23330887747615553,
          0.23330887747615553,
          0.23404255319148937,
          0.23404255319148937,
          0.23477622890682318,
          0.23477622890682318,
          0.235509904622157,
          0.235509904622157,
          0.23697725605282466,
          0.23697725605282466,
          0.2384446074834923,
          0.2384446074834923,
          0.24064563462949376,
          0.24064563462949376,
          0.2413793103448276,
          0.2413793103448276,
          0.24724871606749815,
          0.24724871606749815,
          0.2509170946441673,
          0.2509170946441673,
          0.2516507703595011,
          0.2516507703595011,
          0.2523844460748349,
          0.2523844460748349,
          0.2538517975055026,
          0.2538517975055026,
          0.2553191489361702,
          0.2553191489361702,
          0.2553191489361702,
          0.25605282465150403,
          0.25605282465150403,
          0.25678650036683787,
          0.25678650036683787,
          0.2575201760821717,
          0.2575201760821717,
          0.2582538517975055,
          0.2582538517975055,
          0.260454878943507,
          0.260454878943507,
          0.2619222303741746,
          0.2619222303741746,
          0.26338958180484223,
          0.26338958180484223,
          0.26412325752017607,
          0.26412325752017607,
          0.2648569332355099,
          0.2648569332355099,
          0.26705796038151136,
          0.26705796038151136,
          0.26852531181217903,
          0.26852531181217903,
          0.2714600146735143,
          0.2714600146735143,
          0.2736610418195158,
          0.2736610418195158,
          0.27586206896551724,
          0.27586206896551724,
          0.2773294203961849,
          0.2773294203961849,
          0.2780630961115187,
          0.2780630961115187,
          0.27879677182685253,
          0.27879677182685253,
          0.27953044754218637,
          0.27953044754218637,
          0.2802641232575202,
          0.2802641232575202,
          0.280997798972854,
          0.280997798972854,
          0.2817314746881878,
          0.2817314746881878,
          0.28319882611885544,
          0.28319882611885544,
          0.28539985326485695,
          0.28539985326485695,
          0.28833455612619224,
          0.28833455612619224,
          0.28980190755685986,
          0.28980190755685986,
          0.29273661041819515,
          0.29273661041819515,
          0.2942039618488628,
          0.2942039618488628,
          0.2949376375641966,
          0.2949376375641966,
          0.29567131327953045,
          0.29567131327953045,
          0.29860601614086574,
          0.29860601614086574,
          0.2993396918561996,
          0.2993396918561996,
          0.3008070432868672,
          0.3008070432868672,
          0.30154071900220103,
          0.30154071900220103,
          0.30227439471753487,
          0.30227439471753487,
          0.3044754218635363,
          0.3044754218635363,
          0.30594277329420394,
          0.30594277329420394,
          0.3066764490095378,
          0.3066764490095378,
          0.3074101247248716,
          0.3074101247248716,
          0.30887747615553923,
          0.30887747615553923,
          0.30961115187087307,
          0.30961115187087307,
          0.3103448275862069,
          0.3103448275862069,
          0.31548055759354365,
          0.31548055759354365,
          0.31694790902421127,
          0.31694790902421127,
          0.3176815847395451,
          0.3176815847395451,
          0.3191489361702128,
          0.3191489361702128,
          0.31988261188554656,
          0.31988261188554656,
          0.32281731474688186,
          0.32281731474688186,
          0.3235509904622157,
          0.3235509904622157,
          0.32575201760821715,
          0.32575201760821715,
          0.33162142333088773,
          0.33162142333088773,
          0.33235509904622157,
          0.33235509904622157,
          0.3338224504768892,
          0.3338224504768892,
          0.338958180484226,
          0.338958180484226,
          0.33969185619955977,
          0.33969185619955977,
          0.3404255319148936,
          0.3404255319148936,
          0.34409391049156274,
          0.34409391049156274,
          0.34702861335289803,
          0.34702861335289803,
          0.34849596478356565,
          0.34849596478356565,
          0.3499633162142333,
          0.3499633162142333,
          0.35069699192956716,
          0.35069699192956716,
          0.3521643433602348,
          0.3521643433602348,
          0.3528980190755686,
          0.3528980190755686,
          0.35436537050623623,
          0.35436537050623623,
          0.35509904622157007,
          0.35509904622157007,
          0.3558327219369039,
          0.3558327219369039,
          0.3573000733675715,
          0.3573000733675715,
          0.3602347762289068,
          0.3602347762289068,
          0.36096845194424065,
          0.36096845194424065,
          0.3617021276595745,
          0.3617021276595745,
          0.36243580337490827,
          0.36243580337490827,
          0.36537050623624356,
          0.36537050623624356,
          0.3690388848129127,
          0.3690388848129127,
          0.36977256052824653,
          0.36977256052824653,
          0.371973587674248,
          0.371973587674248,
          0.37417461482024944,
          0.37417461482024944,
          0.3756419662509171,
          0.3756419662509171,
          0.3763756419662509,
          0.3763756419662509,
          0.37784299339691857,
          0.37784299339691857,
          0.3785766691122524,
          0.3785766691122524,
          0.3793103448275862,
          0.3793103448275862,
          0.38004402054292,
          0.38004402054292,
          0.3815113719735877,
          0.3815113719735877,
          0.3822450476889215,
          0.3822450476889215,
          0.3829787234042553,
          0.3829787234042553,
          0.384446074834923,
          0.384446074834923,
          0.3859134262655906,
          0.3859134262655906,
          0.3873807776962582,
          0.3873807776962582,
          0.3888481291269259,
          0.3888481291269259,
          0.39398385913426265,
          0.39398385913426265,
          0.39691856199559794,
          0.39691856199559794,
          0.3983859134262656,
          0.3983859134262656,
          0.3991195891415994,
          0.3991195891415994,
          0.39985326485693323,
          0.39985326485693323,
          0.40058694057226707,
          0.40058694057226707,
          0.4013206162876009,
          0.4013206162876009,
          0.4020542920029347,
          0.4020542920029347,
          0.40425531914893614,
          0.40425531914893614,
          0.40498899486427,
          0.40498899486427,
          0.4086573734409391,
          0.4086573734409391,
          0.41085840058694056,
          0.41085840058694056,
          0.4115920763022744,
          0.4115920763022744,
          0.41232575201760824,
          0.41232575201760824,
          0.413059427732942,
          0.413059427732942,
          0.4145267791636097,
          0.4145267791636097,
          0.4189288334556126,
          0.4189288334556126,
          0.41966250917094644,
          0.41966250917094644,
          0.42112986060161406,
          0.42112986060161406,
          0.42259721203228173,
          0.42259721203228173,
          0.42333088774761557,
          0.42333088774761557,
          0.4247982391782832,
          0.4247982391782832,
          0.425531914893617,
          0.425531914893617,
          0.42626559060895086,
          0.42626559060895086,
          0.4277329420396185,
          0.4277329420396185,
          0.4284666177549523,
          0.4284666177549523,
          0.43066764490095377,
          0.43066764490095377,
          0.4314013206162876,
          0.4314013206162876,
          0.43213499633162145,
          0.43213499633162145,
          0.43360234776228906,
          0.43360234776228906,
          0.43506969919295674,
          0.43506969919295674,
          0.4358033749082905,
          0.4358033749082905,
          0.43653705062362436,
          0.43653705062362436,
          0.4387380777696258,
          0.4387380777696258,
          0.44093910491562727,
          0.44093910491562727,
          0.4416727806309611,
          0.4416727806309611,
          0.4431401320616288,
          0.4431401320616288,
          0.44534115920763023,
          0.44534115920763023,
          0.44607483492296407,
          0.44607483492296407,
          0.44680851063829785,
          0.44680851063829785,
          0.4475421863536317,
          0.4475421863536317,
          0.44900953778429936,
          0.44900953778429936,
          0.44974321349963314,
          0.44974321349963314,
          0.450476889214967,
          0.450476889214967,
          0.4512105649303008,
          0.4512105649303008,
          0.45194424064563465,
          0.45194424064563465,
          0.45341159207630227,
          0.45341159207630227,
          0.45487894350696995,
          0.45487894350696995,
          0.4556126192223037,
          0.4556126192223037,
          0.45634629493763756,
          0.45634629493763756,
          0.4570799706529714,
          0.4570799706529714,
          0.458547322083639,
          0.458547322083639,
          0.45928099779897286,
          0.45928099779897286,
          0.4607483492296405,
          0.4607483492296405,
          0.462949376375642,
          0.462949376375642,
          0.4644167278063096,
          0.4644167278063096,
          0.46515040352164344,
          0.46515040352164344,
          0.46808510638297873,
          0.46808510638297873,
          0.46881878209831257,
          0.46881878209831257,
          0.46955245781364635,
          0.46955245781364635,
          0.4702861335289802,
          0.4702861335289802,
          0.471019809244314,
          0.471019809244314,
          0.47175348495964786,
          0.47175348495964786,
          0.47248716067498164,
          0.47248716067498164,
          0.4739545121056493,
          0.4739545121056493,
          0.4768892149669846,
          0.4768892149669846,
          0.4798239178283199,
          0.4798239178283199,
          0.48202494497432136,
          0.48202494497432136,
          0.4937637564196625,
          0.4937637564196625,
          0.4974321349963316,
          0.4974321349963316,
          0.5099046221570066,
          0.5099046221570066,
          0.5121056493030081,
          0.5121056493030081,
          0.532648569332355,
          0.532648569332355,
          0.5502567865003668,
          0.5502567865003668,
          0.5509904622157007,
          0.5509904622157007,
          0.5517241379310345,
          0.5517241379310345,
          0.5524578136463683,
          0.5524578136463683,
          0.5531914893617021,
          0.5531914893617021,
          0.5561261922230374,
          0.5561261922230374,
          0.5656639765223771,
          0.5656639765223771,
          0.59501100513573,
          0.59501100513573,
          0.6104181951577403,
          0.6104181951577403,
          0.6140865737344093,
          0.6140865737344093,
          0.6214233308877476,
          0.6228906823184153,
          0.632428466617755,
          0.632428466617755,
          0.661041819515774,
          0.6625091709464417,
          0.7219369038884813,
          0.723404255319149,
          0.7395451210564931,
          0.7410124724871606,
          0.7454145267791636,
          0.7468818782098312,
          0.8231841526045488,
          0.8246515040352165,
          0.9207630227439472,
          0.9222303741746148,
          0.9743213499633162,
          0.9757887013939839,
          0.9816581071166545,
          0.983125458547322,
          1.0
        ],
        "tpr": [
          0.0,
          0.0007336757153338225,
          0.015407190022010272,
          0.015407190022010272,
          0.06676449009537784,
          0.06676449009537784,
          0.0748349229640499,
          0.0748349229640499,
          0.07850330154071901,
          0.07850330154071901,
          0.08877476155539252,
          0.08877476155539252,
          0.09391049156272928,
          0.09391049156272928,
          0.0946441672780631,
          0.0946441672780631,
          0.09537784299339692,
          0.09537784299339692,
          0.09757887013939838,
          0.09757887013939838,
          0.0983125458547322,
          0.0983125458547322,
          0.09904622157006603,
          0.09904622157006603,
          0.09977989728539985,
          0.09977989728539985,
          0.10051357300073367,
          0.10051357300073367,
          0.1012472487160675,
          0.1012472487160675,
          0.10271460014673514,
          0.10271460014673514,
          0.10418195157740279,
          0.10418195157740279,
          0.10491562729273661,
          0.10491562729273661,
          0.1078503301540719,
          0.1078503301540719,
          0.11005135730007337,
          0.11005135730007337,
          0.1107850330154072,
          0.1107850330154072,
          0.11151870873074102,
          0.11151870873074102,
          0.11738811445341159,
          0.11738811445341159,
          0.11885546588407923,
          0.11885546588407923,
          0.11958914159941306,
          0.11958914159941306,
          0.12032281731474688,
          0.12032281731474688,
          0.12179016874541453,
          0.12179016874541453,
          0.12252384446074835,
          0.12252384446074835,
          0.1305942773294204,
          0.1305942773294204,
          0.13206162876008803,
          0.13206162876008803,
          0.13279530447542187,
          0.13279530447542187,
          0.13499633162142333,
          0.13499633162142333,
          0.13573000733675716,
          0.13573000733675716,
          0.1438004402054292,
          0.1438004402054292,
          0.1504035216434336,
          0.1504035216434336,
          0.15113719735876743,
          0.15113719735876743,
          0.15480557593543653,
          0.15480557593543653,
          0.16287600880410857,
          0.16287600880410857,
          0.17168011738811445,
          0.17168011738811445,
          0.18415260454878943,
          0.18415260454878943,
          0.24724871606749815,
          0.24724871606749815,
          0.24944974321349964,
          0.24944974321349964,
          0.2516507703595011,
          0.2516507703595011,
          0.26412325752017607,
          0.26412325752017607,
          0.26559060895084374,
          0.26559060895084374,
          0.2677916360968452,
          0.2692589875275128,
          0.2846661775495231,
          0.2846661775495231,
          0.2993396918561996,
          0.2993396918561996,
          0.3037417461482025,
          0.3037417461482025,
          0.3374908290535583,
          0.3374908290535583,
          0.33822450476889215,
          0.33822450476889215,
          0.34115920763022745,
          0.34115920763022745,
          0.35143066764490094,
          0.35143066764490094,
          0.3587674247982392,
          0.3587674247982392,
          0.36977256052824653,
          0.36977256052824653,
          0.3749082905355833,
          0.3749082905355833,
          0.37710931768158473,
          0.37710931768158473,
          0.3859134262655906,
          0.3859134262655906,
          0.38811445341159206,
          0.38811445341159206,
          0.4013206162876009,
          0.4013206162876009,
          0.4020542920029347,
          0.4020542920029347,
          0.40352164343360236,
          0.40352164343360236,
          0.41232575201760824,
          0.41232575201760824,
          0.4181951577402788,
          0.4181951577402788,
          0.4189288334556126,
          0.4189288334556126,
          0.41966250917094644,
          0.41966250917094644,
          0.425531914893617,
          0.425531914893617,
          0.42920029347028615,
          0.42920029347028615,
          0.4343360234776229,
          0.4343360234776229,
          0.4431401320616288,
          0.4431401320616288,
          0.45341159207630227,
          0.45341159207630227,
          0.4556126192223037,
          0.4556126192223037,
          0.4570799706529714,
          0.4570799706529714,
          0.45928099779897286,
          0.45928099779897286,
          0.46221570066030815,
          0.46221570066030815,
          0.462949376375642,
          0.462949376375642,
          0.46808510638297873,
          0.46808510638297873,
          0.47542186353631694,
          0.47542186353631694,
          0.4776228906823184,
          0.4776228906823184,
          0.4783565663976522,
          0.4783565663976522,
          0.47909024211298606,
          0.47909024211298606,
          0.5003668378576669,
          0.5003668378576669,
          0.5011005135730008,
          0.5011005135730008,
          0.5047688921496698,
          0.5047688921496698,
          0.5150403521643434,
          0.5150403521643434,
          0.5187087307410124,
          0.5187087307410124,
          0.520909757887014,
          0.520909757887014,
          0.5275128393250184,
          0.5275128393250184,
          0.5311812179016875,
          0.5311812179016875,
          0.5319148936170213,
          0.5319148936170213,
          0.5333822450476889,
          0.5333822450476889,
          0.5348495964783566,
          0.5348495964783566,
          0.5392516507703595,
          0.5392516507703595,
          0.541452677916361,
          0.541452677916361,
          0.5421863536316948,
          0.5421863536316948,
          0.5451210564930301,
          0.5451210564930301,
          0.5458547322083639,
          0.5458547322083639,
          0.5531914893617021,
          0.5531914893617021,
          0.5553925165077036,
          0.5553925165077036,
          0.5568598679383713,
          0.5568598679383713,
          0.5590608950843727,
          0.5590608950843727,
          0.5605282465150404,
          0.5605282465150404,
          0.5627292736610419,
          0.5627292736610419,
          0.5671313279530448,
          0.5671313279530448,
          0.5678650036683786,
          0.5678650036683786,
          0.57006603081438,
          0.57006603081438,
          0.5737344093910491,
          0.5737344093910491,
          0.5766691122523845,
          0.5766691122523845,
          0.578136463683052,
          0.578136463683052,
          0.5788701393983859,
          0.5788701393983859,
          0.5818048422597212,
          0.5818048422597212,
          0.5862068965517241,
          0.5862068965517241,
          0.5928099779897286,
          0.5928099779897286,
          0.5935436537050623,
          0.5986793837123991,
          0.5986793837123991,
          0.6052824651504035,
          0.6052824651504035,
          0.607483492296405,
          0.607483492296405,
          0.6082171680117389,
          0.6082171680117389,
          0.6104181951577403,
          0.6104181951577403,
          0.6111518708730741,
          0.6111518708730741,
          0.6126192223037418,
          0.6126192223037418,
          0.6140865737344093,
          0.6140865737344093,
          0.6148202494497432,
          0.6148202494497432,
          0.615553925165077,
          0.615553925165077,
          0.6170212765957447,
          0.6170212765957447,
          0.6184886280264124,
          0.6184886280264124,
          0.6192223037417461,
          0.6192223037417461,
          0.6206896551724138,
          0.6206896551724138,
          0.6221570066030815,
          0.6221570066030815,
          0.6228906823184153,
          0.6228906823184153,
          0.623624358033749,
          0.623624358033749,
          0.6250917094644167,
          0.6250917094644167,
          0.6272927366104182,
          0.6272927366104182,
          0.6280264123257521,
          0.6280264123257521,
          0.6287600880410859,
          0.6287600880410859,
          0.6338958180484225,
          0.6338958180484225,
          0.6375641966250917,
          0.6375641966250917,
          0.6390315480557593,
          0.6390315480557593,
          0.6419662509170947,
          0.6419662509170947,
          0.6426999266324285,
          0.6426999266324285,
          0.6507703595011005,
          0.6507703595011005,
          0.6515040352164343,
          0.6515040352164343,
          0.6522377109317682,
          0.6522377109317682,
          0.652971386647102,
          0.652971386647102,
          0.6544387380777696,
          0.6544387380777696,
          0.6581071166544388,
          0.6581071166544388,
          0.6603081438004402,
          0.6603081438004402,
          0.661041819515774,
          0.661041819515774,
          0.6625091709464417,
          0.6625091709464417,
          0.6661775495231108,
          0.6661775495231108,
          0.6676449009537784,
          0.6676449009537784,
          0.6683785766691123,
          0.6683785766691123,
          0.6698459280997799,
          0.6698459280997799,
          0.6705796038151137,
          0.6705796038151137,
          0.6727806309611152,
          0.6727806309611152,
          0.673514306676449,
          0.673514306676449,
          0.6749816581071166,
          0.6749816581071166,
          0.6771826852531181,
          0.6771826852531181,
          0.677916360968452,
          0.677916360968452,
          0.6786500366837858,
          0.6786500366837858,
          0.6793837123991195,
          0.6793837123991195,
          0.6808510638297872,
          0.6808510638297872,
          0.6815847395451211,
          0.6815847395451211,
          0.6889214966984593,
          0.6889214966984593,
          0.6903888481291269,
          0.6903888481291269,
          0.6911225238444607,
          0.6911225238444607,
          0.6940572267057961,
          0.6940572267057961,
          0.6962582538517975,
          0.6962582538517975,
          0.6969919295671313,
          0.6969919295671313,
          0.6977256052824652,
          0.6977256052824652,
          0.698459280997799,
          0.698459280997799,
          0.6991929567131328,
          0.6991929567131328,
          0.7013939838591343,
          0.7013939838591343,
          0.7028613352898019,
          0.7028613352898019,
          0.7057960381511372,
          0.7057960381511372,
          0.706529713866471,
          0.706529713866471,
          0.7072633895818048,
          0.7072633895818048,
          0.7079970652971387,
          0.7079970652971387,
          0.7094644167278064,
          0.7094644167278064,
          0.7138664710198093,
          0.7138664710198093,
          0.714600146735143,
          0.714600146735143,
          0.7153338224504769,
          0.7153338224504769,
          0.7175348495964784,
          0.7175348495964784,
          0.7182685253118122,
          0.7182685253118122,
          0.719002201027146,
          0.719002201027146,
          0.7197358767424799,
          0.7197358767424799,
          0.7212032281731474,
          0.7212032281731474,
          0.7219369038884813,
          0.7219369038884813,
          0.723404255319149,
          0.723404255319149,
          0.7241379310344828,
          0.7241379310344828,
          0.7256052824651504,
          0.7256052824651504,
          0.7263389581804842,
          0.7263389581804842,
          0.727072633895818,
          0.727072633895818,
          0.7278063096111519,
          0.7278063096111519,
          0.7285399853264857,
          0.7285399853264857,
          0.7292736610418196,
          0.7292736610418196,
          0.731474688187821,
          0.731474688187821,
          0.7329420396184886,
          0.7329420396184886,
          0.7358767424798239,
          0.7358767424798239,
          0.7380777696258254,
          0.7380777696258254,
          0.7395451210564931,
          0.7395451210564931,
          0.7402787967718268,
          0.7402787967718268,
          0.7410124724871606,
          0.7410124724871606,
          0.7432134996331622,
          0.7432134996331622,
          0.7454145267791636,
          0.7454145267791636,
          0.7461482024944974,
          0.7461482024944974,
          0.7468818782098312,
          0.7468818782098312,
          0.7483492296404989,
          0.7483492296404989,
          0.7490829053558328,
          0.7490829053558328,
          0.7498165810711666,
          0.7498165810711666,
          0.7512839325018342,
          0.7534849596478357,
          0.7534849596478357,
          0.7542186353631695,
          0.7542186353631695,
          0.7593543653705063,
          0.7593543653705063,
          0.7608217168011738,
          0.7608217168011738,
          0.7622890682318415,
          0.7622890682318415,
          0.764490095377843,
          0.764490095377843,
          0.7659574468085106,
          0.7659574468085106,
          0.7666911225238444,
          0.7666911225238444,
          0.7674247982391783,
          0.7674247982391783,
          0.7696258253851798,
          0.7696258253851798,
          0.7703595011005135,
          0.7703595011005135,
          0.7710931768158474,
          0.7710931768158474,
          0.7740278796771827,
          0.7740278796771827,
          0.7754952311078503,
          0.7754952311078503,
          0.7784299339691856,
          0.7784299339691856,
          0.7791636096845195,
          0.7791636096845195,
          0.7798972853998533,
          0.7798972853998533,
          0.7820983125458547,
          0.7820983125458547,
          0.7835656639765224,
          0.7835656639765224,
          0.7842993396918562,
          0.7842993396918562,
          0.7850330154071901,
          0.7850330154071901,
          0.7857666911225238,
          0.7857666911225238,
          0.789435069699193,
          0.789435069699193,
          0.7909024211298606,
          0.7909024211298606,
          0.7916360968451944,
          0.7916360968451944,
          0.7923697725605282,
          0.7923697725605282,
          0.7945707997065297,
          0.7945707997065297,
          0.7953044754218636,
          0.7953044754218636,
          0.7960381511371973,
          0.7960381511371973,
          0.7967718268525312,
          0.7967718268525312,
          0.797505502567865,
          0.797505502567865,
          0.7982391782831988,
          0.7982391782831988,
          0.7997065297138665,
          0.7997065297138665,
          0.8004402054292002,
          0.8004402054292002,
          0.8019075568598679,
          0.8019075568598679,
          0.8026412325752018,
          0.8026412325752018,
          0.8041085840058694,
          0.8041085840058694,
          0.8048422597212033,
          0.8048422597212033,
          0.8070432868672047,
          0.8070432868672047,
          0.8077769625825385,
          0.8077769625825385,
          0.8114453411592076,
          0.8114453411592076,
          0.8121790168745414,
          0.8121790168745414,
          0.8129126925898753,
          0.8129126925898753,
          0.8173147468818782,
          0.8173147468818782,
          0.818048422597212,
          0.818048422597212,
          0.8187820983125459,
          0.8187820983125459,
          0.8195157740278797,
          0.8195157740278797,
          0.8217168011738811,
          0.8217168011738811,
          0.822450476889215,
          0.822450476889215,
          0.8231841526045488,
          0.8231841526045488,
          0.8246515040352165,
          0.8246515040352165,
          0.8253851797505503,
          0.8253851797505503,
          0.8275862068965517,
          0.8275862068965517,
          0.8283198826118855,
          0.8283198826118855,
          0.8297872340425532,
          0.8297872340425532,
          0.8305209097578871,
          0.8305209097578871,
          0.8312545854732208,
          0.8312545854732208,
          0.8334556126192223,
          0.8334556126192223,
          0.8341892883345561,
          0.8341892883345561,
          0.8378576669112252,
          0.8378576669112252,
          0.8385913426265591,
          0.8385913426265591,
          0.8393250183418929,
          0.8393250183418929,
          0.8400586940572267,
          0.8400586940572267,
          0.8407923697725606,
          0.8407923697725606,
          0.8415260454878943,
          0.8415260454878943,
          0.842993396918562,
          0.842993396918562,
          0.8437270726338958,
          0.8437270726338958,
          0.8444607483492297,
          0.8444607483492297,
          0.8459280997798972,
          0.8459280997798972,
          0.8466617754952311,
          0.8466617754952311,
          0.8473954512105649,
          0.8473954512105649,
          0.8495964783565664,
          0.8495964783565664,
          0.8503301540719003,
          0.8503301540719003,
          0.851063829787234,
          0.851063829787234,
          0.8517975055025678,
          0.8517975055025678,
          0.8532648569332355,
          0.8532648569332355,
          0.8547322083639032,
          0.8547322083639032,
          0.855465884079237,
          0.855465884079237,
          0.8561995597945709,
          0.8561995597945709,
          0.8569332355099046,
          0.8569332355099046,
          0.8576669112252384,
          0.8576669112252384,
          0.8598679383712399,
          0.8598679383712399,
          0.8613352898019075,
          0.8613352898019075,
          0.8620689655172413,
          0.8620689655172413,
          0.8628026412325752,
          0.8628026412325752,
          0.863536316947909,
          0.863536316947909,
          0.8650036683785767,
          0.8650036683785767,
          0.8664710198092443,
          0.8664710198092443,
          0.8672046955245781,
          0.8672046955245781,
          0.8679383712399119,
          0.8679383712399119,
          0.8686720469552458,
          0.8686720469552458,
          0.8694057226705796,
          0.8694057226705796,
          0.8701393983859135,
          0.8701393983859135,
          0.8708730741012473,
          0.8708730741012473,
          0.8723404255319149,
          0.8723404255319149,
          0.8738077769625825,
          0.8738077769625825,
          0.8745414526779164,
          0.8745414526779164,
          0.8752751283932502,
          0.8752751283932502,
          0.8760088041085841,
          0.8760088041085841,
          0.8767424798239178,
          0.8767424798239178,
          0.880410858400587,
          0.880410858400587,
          0.8818782098312545,
          0.8818782098312545,
          0.8826118855465884,
          0.8826118855465884,
          0.8848129126925899,
          0.8848129126925899,
          0.8855465884079237,
          0.8855465884079237,
          0.8870139398385913,
          0.8870139398385913,
          0.888481291269259,
          0.888481291269259,
          0.8892149669845928,
          0.8892149669845928,
          0.8921496698459281,
          0.8921496698459281,
          0.8936170212765957,
          0.8936170212765957,
          0.8958180484225972,
          0.8958180484225972,
          0.8987527512839325,
          0.8987527512839325,
          0.9002201027146002,
          0.9002201027146002,
          0.9024211298606016,
          0.9024211298606016,
          0.9038884812912693,
          0.9038884812912693,
          0.9060895084372708,
          0.9060895084372708,
          0.9068231841526045,
          0.9068231841526045,
          0.9097578870139399,
          0.9097578870139399,
          0.9104915627292737,
          0.9104915627292737,
          0.9112252384446075,
          0.9112252384446075,
          0.9119589141599413,
          0.9119589141599413,
          0.9163609684519443,
          0.9163609684519443,
          0.9185619955979457,
          0.9185619955979457,
          0.9200293470286134,
          0.9200293470286134,
          0.9222303741746148,
          0.9222303741746148,
          0.9251650770359501,
          0.9251650770359501,
          0.9273661041819515,
          0.9273661041819515,
          0.9280997798972854,
          0.9280997798972854,
          0.9325018341892883,
          0.9325018341892883,
          0.9347028613352898,
          0.9347028613352898,
          0.9361702127659575,
          0.9361702127659575,
          0.9369038884812912,
          0.9369038884812912,
          0.9376375641966251,
          0.9376375641966251,
          0.9383712399119589,
          0.9383712399119589,
          0.9398385913426266,
          0.9398385913426266,
          0.9435069699192957,
          0.9435069699192957,
          0.9479090242112986,
          0.9479090242112986,
          0.9523110785033015,
          0.9523110785033015,
          0.9552457813646368,
          0.9552457813646368,
          0.9559794570799707,
          0.9559794570799707,
          0.9618488628026413,
          0.9618488628026413,
          0.9633162142333089,
          0.9633162142333089,
          0.9647835656639765,
          0.9647835656639765,
          0.9677182685253118,
          0.9677182685253118,
          0.9684519442406456,
          0.9684519442406456,
          0.9691856199559794,
          0.9691856199559794,
          0.971386647101981,
          0.971386647101981,
          0.9728539985326485,
          0.9728539985326485,
          0.9735876742479824,
          0.9735876742479824,
          0.97505502567865,
          0.97505502567865,
          0.9765223771093177,
          0.9765223771093177,
          0.9779897285399853,
          0.9779897285399853,
          0.979457079970653,
          0.979457079970653,
          0.9801907556859868,
          0.9801907556859868,
          0.9809244314013206,
          0.9809244314013206,
          0.9823917828319882,
          0.9823917828319882,
          0.983125458547322,
          0.983125458547322,
          0.9845928099779897,
          0.9845928099779897,
          0.9853264856933236,
          0.9853264856933236,
          0.9860601614086574,
          0.9860601614086574,
          0.9867938371239912,
          0.9867938371239912,
          0.987527512839325,
          0.987527512839325,
          0.9889948642699926,
          0.9889948642699926,
          0.9926632428466617,
          0.9926632428466617,
          0.9933969185619956,
          0.9933969185619956,
          0.9941305942773294,
          0.9941305942773294,
          0.9948642699926632,
          0.9948642699926632,
          0.9963316214233309,
          0.9963316214233309,
          0.9970652971386648,
          0.9970652971386648,
          0.9977989728539985,
          0.9977989728539985,
          0.9985326485693323,
          0.9985326485693323,
          0.9992663242846662,
          0.9992663242846662,
          0.9992663242846662,
          0.9992663242846662,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0,
          1.0
        ],
        "thresholds": [
          Infinity,
          0.4790385663509369,
          0.47836747765541077,
          0.47835204005241394,
          0.4775218665599823,
          0.47750943899154663,
          0.47735053300857544,
          0.47732266783714294,
          0.47721320390701294,
          0.4771835505962372,
          0.4768933355808258,
          0.47687774896621704,
          0.4767703413963318,
          0.47673097252845764,
          0.4767124354839325,
          0.47667548060417175,
          0.4765557646751404,
          0.4764672517776489,
          0.4763236939907074,
          0.4762800633907318,
          0.47624725103378296,
          0.47617051005363464,
          0.4761357307434082,
          0.4761120080947876,
          0.47609707713127136,
          0.4760448634624481,
          0.47603461146354675,
          0.47603264451026917,
          0.47601941227912903,
          0.47590264678001404,
          0.47585755586624146,
          0.4758516550064087,
          0.47582218050956726,
          0.47575271129608154,
          0.4757317006587982,
          0.4757120907306671,
          0.47561711072921753,
          0.4756043255329132,
          0.47549089789390564,
          0.475490540266037,
          0.4754819869995117,
          0.47546815872192383,
          0.47546759247779846,
          0.47545599937438965,
          0.4753781855106354,
          0.47536972165107727,
          0.4753439128398895,
          0.4753425419330597,
          0.4753291606903076,
          0.47532013058662415,
          0.47529008984565735,
          0.47521063685417175,
          0.47517073154449463,
          0.4751145839691162,
          0.47503042221069336,
          0.47492730617523193,
          0.47476115822792053,
          0.4747447073459625,
          0.4747277498245239,
          0.47471609711647034,
          0.47469648718833923,
          0.47469285130500793,
          0.4746401607990265,
          0.4744584262371063,
          0.47443512082099915,
          0.4744078516960144,
          0.47420328855514526,
          0.47416597604751587,
          0.4740597605705261,
          0.4740533232688904,
          0.474048376083374,
          0.4740270674228668,
          0.47399023175239563,
          0.47392839193344116,
          0.47384220361709595,
          0.4738312065601349,
          0.47344860434532166,
          0.4734383523464203,
          0.472894549369812,
          0.4728798270225525,
          0.4717864692211151,
          0.47178059816360474,
          0.4717494547367096,
          0.47174498438835144,
          0.4716944098472595,
          0.47168946266174316,
          0.47148287296295166,
          0.47147560119628906,
          0.47145020961761475,
          0.47143250703811646,
          0.47140321135520935,
          0.47139278054237366,
          0.47122707962989807,
          0.47121647000312805,
          0.4710063636302948,
          0.4709816575050354,
          0.470914363861084,
          0.4709010124206543,
          0.4704955518245697,
          0.47048845887184143,
          0.4704752266407013,
          0.4704732298851013,
          0.47045060992240906,
          0.4704463481903076,
          0.47020038962364197,
          0.4701717495918274,
          0.4700879454612732,
          0.4700843095779419,
          0.46995848417282104,
          0.4699089825153351,
          0.46983689069747925,
          0.4698362350463867,
          0.4698279798030853,
          0.46981894969940186,
          0.4696045219898224,
          0.4696037173271179,
          0.4695878326892853,
          0.46957024931907654,
          0.46934792399406433,
          0.4693300724029541,
          0.46930617094039917,
          0.4692872166633606,
          0.4692747890949249,
          0.46927252411842346,
          0.4691771864891052,
          0.4691756069660187,
          0.4691055119037628,
          0.4691035747528076,
          0.4691028892993927,
          0.46908244490623474,
          0.46905890107154846,
          0.4690101146697998,
          0.46892645955085754,
          0.4689238965511322,
          0.4689006209373474,
          0.4688986539840698,
          0.4688100218772888,
          0.46880173683166504,
          0.46871232986450195,
          0.4687095880508423,
          0.4685973525047302,
          0.46859532594680786,
          0.4685741662979126,
          0.4685696065425873,
          0.46856147050857544,
          0.46855756640434265,
          0.4685542583465576,
          0.4685511291027069,
          0.4685160517692566,
          0.46850940585136414,
          0.46849536895751953,
          0.4684601128101349,
          0.46839576959609985,
          0.468378484249115,
          0.4682525098323822,
          0.46822389960289,
          0.46820583939552307,
          0.4681878983974457,
          0.46818771958351135,
          0.46814244985580444,
          0.46813833713531494,
          0.46813711524009705,
          0.46798473596572876,
          0.4679621756076813,
          0.4679575264453888,
          0.4679565727710724,
          0.46790528297424316,
          0.46787771582603455,
          0.4678169786930084,
          0.4678109884262085,
          0.4677801728248596,
          0.46777406334877014,
          0.46775996685028076,
          0.4677365720272064,
          0.4676835536956787,
          0.46768301725387573,
          0.4676690101623535,
          0.4676620066165924,
          0.4676573872566223,
          0.4676511883735657,
          0.4676503539085388,
          0.4676501154899597,
          0.46764227747917175,
          0.46762099862098694,
          0.46759241819381714,
          0.4675779938697815,
          0.46756356954574585,
          0.4675453007221222,
          0.4675440192222595,
          0.46754226088523865,
          0.4675268232822418,
          0.46751949191093445,
          0.46751880645751953,
          0.46751055121421814,
          0.46745485067367554,
          0.4674486219882965,
          0.4674438238143921,
          0.46743538975715637,
          0.46742865443229675,
          0.46740955114364624,
          0.4673963487148285,
          0.4673846662044525,
          0.46737343072891235,
          0.46736058592796326,
          0.46733149886131287,
          0.46733054518699646,
          0.4672861695289612,
          0.4672735035419464,
          0.46725231409072876,
          0.46724995970726013,
          0.4672326445579529,
          0.4672234356403351,
          0.4671998620033264,
          0.4671984016895294,
          0.4671654999256134,
          0.46715518832206726,
          0.46714547276496887,
          0.4671219289302826,
          0.4671195447444916,
          0.46711283922195435,
          0.4670969545841217,
          0.4670923054218292,
          0.4670732915401459,
          0.46706265211105347,
          0.4670228958129883,
          0.4670164883136749,
          0.46701580286026,
          0.4669952094554901,
          0.4669865369796753,
          0.46691200137138367,
          0.46690407395362854,
          0.46688660979270935,
          0.4668739438056946,
          0.46687227487564087,
          0.4668647348880768,
          0.4668455421924591,
          0.4668439030647278,
          0.46684131026268005,
          0.4668312668800354,
          0.46682608127593994,
          0.466817706823349,
          0.46678319573402405,
          0.46677517890930176,
          0.4667731821537018,
          0.4667716324329376,
          0.4667697846889496,
          0.46675905585289,
          0.46674951910972595,
          0.46674224734306335,
          0.46672603487968445,
          0.4667212963104248,
          0.4667198359966278,
          0.46670830249786377,
          0.46669408679008484,
          0.4666723310947418,
          0.46666011214256287,
          0.46665409207344055,
          0.46665313839912415,
          0.4666513502597809,
          0.46664679050445557,
          0.4666343033313751,
          0.4666215777397156,
          0.46659114956855774,
          0.4665371775627136,
          0.46643730998039246,
          0.4664240777492523,
          0.4664163291454315,
          0.46641334891319275,
          0.4664073586463928,
          0.46636712551116943,
          0.4663614332675934,
          0.46631109714508057,
          0.466295063495636,
          0.46628639101982117,
          0.46627068519592285,
          0.4662565588951111,
          0.46625351905822754,
          0.46624645590782166,
          0.46624234318733215,
          0.46620315313339233,
          0.4661986231803894,
          0.46619826555252075,
          0.4661965072154999,
          0.46619150042533875,
          0.4661882221698761,
          0.4661869704723358,
          0.4661847949028015,
          0.46617844700813293,
          0.4661480188369751,
          0.46612435579299927,
          0.4661232829093933,
          0.46611469984054565,
          0.4660966396331787,
          0.4660916030406952,
          0.46607229113578796,
          0.46606341004371643,
          0.4660608172416687,
          0.4660382866859436,
          0.46602383255958557,
          0.4660196304321289,
          0.4660158157348633,
          0.46601051092147827,
          0.46601003408432007,
          0.466004878282547,
          0.46596959233283997,
          0.46596938371658325,
          0.465964674949646,
          0.4659457802772522,
          0.4659237861633301,
          0.4659237265586853,
          0.4659211337566376,
          0.465918630361557,
          0.4659048318862915,
          0.46585437655448914,
          0.4658215045928955,
          0.46581918001174927,
          0.4658094048500061,
          0.46579229831695557,
          0.4657883942127228,
          0.4657841622829437,
          0.46575817465782166,
          0.46573373675346375,
          0.4657251238822937,
          0.46571671962738037,
          0.465705931186676,
          0.46563422679901123,
          0.465628981590271,
          0.4656275510787964,
          0.4656100571155548,
          0.4656040072441101,
          0.4655223786830902,
          0.46546733379364014,
          0.4654654860496521,
          0.46544504165649414,
          0.4654253423213959,
          0.4654131829738617,
          0.46539387106895447,
          0.46538978815078735,
          0.46538853645324707,
          0.46538040041923523,
          0.46537259221076965,
          0.465366393327713,
          0.4653071165084839,
          0.465293288230896,
          0.4652749001979828,
          0.465244859457016,
          0.46524015069007874,
          0.4652113914489746,
          0.4651564359664917,
          0.4651523232460022,
          0.46513503789901733,
          0.4651336669921875,
          0.46513354778289795,
          0.4651322066783905,
          0.4651296138763428,
          0.46512022614479065,
          0.4650861322879791,
          0.46504583954811096,
          0.4650297462940216,
          0.4650115370750427,
          0.46498751640319824,
          0.46498626470565796,
          0.464944452047348,
          0.4649268388748169,
          0.4649171829223633,
          0.46489253640174866,
          0.4648910462856293,
          0.46483489871025085,
          0.4648248851299286,
          0.4648248255252838,
          0.46480557322502136,
          0.4647751748561859,
          0.46476826071739197,
          0.4647611677646637,
          0.46471142768859863,
          0.4646852910518646,
          0.4646652042865753,
          0.46465355157852173,
          0.4646424353122711,
          0.46462440490722656,
          0.46457165479660034,
          0.4645625054836273,
          0.4645531177520752,
          0.464547723531723,
          0.4645456075668335,
          0.46450430154800415,
          0.4645031988620758,
          0.4644882380962372,
          0.4644293189048767,
          0.4644247591495514,
          0.4644243121147156,
          0.4643760323524475,
          0.4643188416957855,
          0.46426311135292053,
          0.46425962448120117,
          0.464231938123703,
          0.4641859829425812,
          0.46417784690856934,
          0.46416565775871277,
          0.46416163444519043,
          0.46410927176475525,
          0.4640747308731079,
          0.4640449583530426,
          0.464025616645813,
          0.463993102312088,
          0.4639642536640167,
          0.4639616012573242,
          0.46395131945610046,
          0.46391117572784424,
          0.4639095962047577,
          0.46385031938552856,
          0.46384555101394653,
          0.4638383686542511,
          0.46382859349250793,
          0.4638247489929199,
          0.4637933075428009,
          0.4637523591518402,
          0.4637511372566223,
          0.46373236179351807,
          0.4637281000614166,
          0.46371981501579285,
          0.46371200680732727,
          0.4637104570865631,
          0.4637060761451721,
          0.46366673707962036,
          0.46366652846336365,
          0.4636308550834656,
          0.4636293351650238,
          0.46362197399139404,
          0.46359744668006897,
          0.46358007192611694,
          0.46356314420700073,
          0.46353763341903687,
          0.4635249972343445,
          0.46352410316467285,
          0.46352288126945496,
          0.463522732257843,
          0.463518351316452,
          0.46348458528518677,
          0.46346405148506165,
          0.46345698833465576,
          0.46344998478889465,
          0.4634448289871216,
          0.4633973240852356,
          0.46336567401885986,
          0.46334779262542725,
          0.4633212685585022,
          0.46330249309539795,
          0.46326351165771484,
          0.4632505178451538,
          0.46324825286865234,
          0.4632429778575897,
          0.4632428288459778,
          0.4632314145565033,
          0.4632234573364258,
          0.46321555972099304,
          0.4632132947444916,
          0.4632118344306946,
          0.4632088840007782,
          0.4631998538970947,
          0.4631952941417694,
          0.4631829857826233,
          0.46317848563194275,
          0.46316277980804443,
          0.463135302066803,
          0.46310219168663025,
          0.4630938768386841,
          0.46306878328323364,
          0.4630585312843323,
          0.46305274963378906,
          0.4630495309829712,
          0.46301934123039246,
          0.463000625371933,
          0.462976336479187,
          0.46297404170036316,
          0.4629540741443634,
          0.4629487097263336,
          0.46294769644737244,
          0.4629429876804352,
          0.4629245400428772,
          0.46292057633399963,
          0.46291714906692505,
          0.46291497349739075,
          0.4629039764404297,
          0.46289223432540894,
          0.46288594603538513,
          0.46287810802459717,
          0.4628753066062927,
          0.4628710150718689,
          0.4628519117832184,
          0.46284639835357666,
          0.4628337621688843,
          0.46283194422721863,
          0.4628271460533142,
          0.4628234803676605,
          0.4628143608570099,
          0.4627974033355713,
          0.4627951383590698,
          0.4627903997898102,
          0.46279004216194153,
          0.4627741873264313,
          0.4627741575241089,
          0.46277034282684326,
          0.46275511384010315,
          0.4627549648284912,
          0.46275413036346436,
          0.4627445638179779,
          0.462743878364563,
          0.4627429246902466,
          0.4627304673194885,
          0.4627228081226349,
          0.46272093057632446,
          0.4627085030078888,
          0.46269556879997253,
          0.46268802881240845,
          0.4626873731613159,
          0.46268680691719055,
          0.46268364787101746,
          0.46268174052238464,
          0.46265941858291626,
          0.4626582860946655,
          0.46265673637390137,
          0.46264806389808655,
          0.4626443386077881,
          0.4626307785511017,
          0.46260371804237366,
          0.4626013934612274,
          0.46259787678718567,
          0.46258825063705444,
          0.46257922053337097,
          0.46257784962654114,
          0.46254444122314453,
          0.4625389277935028,
          0.4625207483768463,
          0.4625132977962494,
          0.4625096619129181,
          0.46250882744789124,
          0.4625057280063629,
          0.462493896484375,
          0.46248912811279297,
          0.4624881446361542,
          0.4624869227409363,
          0.46248382329940796,
          0.4624829888343811,
          0.46248218417167664,
          0.4624813497066498,
          0.46247193217277527,
          0.462470680475235,
          0.4624677896499634,
          0.46245265007019043,
          0.46244677901268005,
          0.4624403119087219,
          0.4624382555484772,
          0.4624324440956116,
          0.46242767572402954,
          0.46242696046829224,
          0.46242210268974304,
          0.4624175429344177,
          0.46241527795791626,
          0.4624115526676178,
          0.46240198612213135,
          0.4623875319957733,
          0.4623746871948242,
          0.46235403418540955,
          0.4623514413833618,
          0.4623451232910156,
          0.4623416066169739,
          0.462332159280777,
          0.46232831478118896,
          0.46232128143310547,
          0.46231719851493835,
          0.46230998635292053,
          0.46230724453926086,
          0.4623062312602997,
          0.4623040556907654,
          0.4622991383075714,
          0.4622946083545685,
          0.46229442954063416,
          0.46228644251823425,
          0.462285578250885,
          0.4622827470302582,
          0.46227991580963135,
          0.46226662397384644,
          0.4622640013694763,
          0.4622593820095062,
          0.4622568190097809,
          0.4622567594051361,
          0.46225371956825256,
          0.46225178241729736,
          0.46225082874298096,
          0.46224936842918396,
          0.4622415602207184,
          0.4622364044189453,
          0.46222159266471863,
          0.4622158706188202,
          0.4622148275375366,
          0.4622142016887665,
          0.46219590306282043,
          0.4621937572956085,
          0.46218809485435486,
          0.46218642592430115,
          0.4621764123439789,
          0.4621732831001282,
          0.46217167377471924,
          0.4621664881706238,
          0.4621657431125641,
          0.46216338872909546,
          0.4621453881263733,
          0.46213579177856445,
          0.46213558316230774,
          0.46213021874427795,
          0.46212634444236755,
          0.46212533116340637,
          0.4621235430240631,
          0.4621225595474243,
          0.4621209502220154,
          0.4621208906173706,
          0.46210503578186035,
          0.46210166811943054,
          0.462096631526947,
          0.4620853662490845,
          0.46207812428474426,
          0.46206986904144287,
          0.46206948161125183,
          0.462067574262619,
          0.46206027269363403,
          0.46204301714897156,
          0.46203625202178955,
          0.462025910615921,
          0.4619998335838318,
          0.4619789719581604,
          0.4619627594947815,
          0.4619542956352234,
          0.4619416296482086,
          0.4619297385215759,
          0.4619069993495941,
          0.46184617280960083,
          0.46183159947395325,
          0.46177101135253906,
          0.4617008566856384,
          0.46160566806793213,
          0.4615688920021057,
          0.461453378200531,
          0.46143051981925964,
          0.4614143371582031,
          0.4613807499408722,
          0.4611513316631317,
          0.46114519238471985,
          0.46096372604370117,
          0.4609278738498688,
          0.46081244945526123,
          0.46080824732780457,
          0.4607991576194763,
          0.4607884883880615,
          0.46072614192962646,
          0.46068859100341797,
          0.460666298866272,
          0.4606107771396637,
          0.4605470597743988,
          0.4604908525943756,
          0.46043407917022705,
          0.4603530764579773,
          0.46001139283180237,
          0.45995184779167175,
          0.45988279581069946,
          0.4597451388835907,
          0.4596182703971863,
          0.45960837602615356,
          0.45937997102737427,
          0.45927858352661133,
          0.4591677784919739,
          0.45913344621658325,
          0.4589279890060425,
          0.45891791582107544,
          0.45886436104774475,
          0.4588417410850525,
          0.45872998237609863,
          0.4586964547634125,
          0.458564817905426,
          0.45854803919792175,
          0.45848193764686584,
          0.45847514271736145,
          0.45840856432914734,
          0.45840439200401306,
          0.4583970904350281,
          0.45832666754722595,
          0.45830440521240234,
          0.4582986533641815,
          0.4582460820674896,
          0.4581671357154846,
          0.4579141438007355,
          0.457868754863739,
          0.45777663588523865,
          0.457759827375412,
          0.45757219195365906,
          0.45755574107170105,
          0.45748066902160645,
          0.4573826193809509,
          0.45737186074256897,
          0.45694220066070557,
          0.4566822946071625,
          0.4565594792366028,
          0.45654988288879395,
          0.4564119279384613,
          0.45637866854667664,
          0.45627620816230774,
          0.4560766816139221,
          0.4559440314769745,
          0.45592018961906433,
          0.4558819830417633,
          0.4558704197406769,
          0.45546045899391174,
          0.45522043108940125,
          0.45520520210266113,
          0.4551248252391815,
          0.4550837576389313,
          0.4549473822116852,
          0.4549133777618408,
          0.454785019159317,
          0.4546787738800049,
          0.4544931948184967,
          0.45449182391166687,
          0.4543754458427429,
          0.45436736941337585,
          0.45427337288856506,
          0.45419368147850037,
          0.4541321396827698,
          0.4540429711341858,
          0.4540260136127472,
          0.45388758182525635,
          0.45384669303894043,
          0.45372429490089417,
          0.4537025988101959,
          0.4532613456249237,
          0.45317748188972473,
          0.45309045910835266,
          0.45308607816696167,
          0.4523160457611084,
          0.45227327942848206,
          0.45205673575401306,
          0.4519979953765869,
          0.45108217000961304,
          0.45107975602149963,
          0.45025286078453064,
          0.4502274692058563,
          0.45021888613700867,
          0.45020800828933716,
          0.4501951038837433,
          0.45019474625587463,
          0.45019039511680603,
          0.4501843750476837,
          0.4501798152923584,
          0.4501773715019226,
          0.45012426376342773,
          0.4501127302646637,
          0.4498765170574188,
          0.4498629570007324,
          0.4495702087879181,
          0.4495648443698883,
          0.4494696855545044,
          0.4494568407535553,
          0.44944068789482117,
          0.44943973422050476,
          0.4493575692176819,
          0.4493480324745178,
          0.4493017792701721,
          0.44929975271224976,
          0.44923052191734314,
          0.4492303431034088,
          0.44914504885673523,
          0.44914454221725464,
          0.4491333067417145,
          0.44913262128829956,
          0.4491240084171295,
          0.44912204146385193,
          0.4490126669406891,
          0.4490126371383667,
          0.4488505423069,
          0.4488500952720642,
          0.4486387073993683,
          0.4486382007598877,
          0.4486270844936371,
          0.44862431287765503,
          0.4485354721546173
        ]
      },
      "roc_auc": 0.8462308823109871,
      "optimal_threshold": 0.4656275510787964
    },
    "ttt_model_metatasks": {
      "accuracy_mean": 0.5607599999999999,
      "accuracy_std": 0.13377730151262585,
      "precision_mean": 0.5607599999999999,
      "precision_std": 0.13377730151262585,
      "recall_mean": 0.5607599999999999,
      "recall_std": 0.13377730151262585,
      "macro_f1_mean": 0.4288459983543243,
      "macro_f1_std": 0.17914707854444434,
      "mcc_mean": 0.19015715209034018,
      "mcc_std": 0.24935688101540443,
      "confusion_matrix": [
        [
          1249,
          1
        ],
        [
          1173,
          77
        ]
      ],
      "roc_curve": {
        "fpr": [
          0.0,
          0.0,
          0.0,
          0.0008,
          0.0008,
          0.0016,
          0.0016,
          0.0024,
          0.0024,
          0.0032,
          0.0032,
          0.004,
          0.004,
          0.0048,
          0.0048,
          0.0056,
          0.0056,
          0.0064,
          0.0064,
          0.0064,
          0.0064,
          0.0072,
          0.0072,
          0.008,
          0.008,
          0.0088,
          0.0088,
          0.0096,
          0.0096,
          0.0096,
          0.0096,
          0.0096,
          0.0104,
          0.0104,
          0.0112,
          0.0112,
          0.012,
          0.012,
          0.0128,
          0.0128,
          0.0136,
          0.0136,
          0.0144,
          0.0144,
          0.0152,
          0.0152,
          0.016,
          0.016,
          0.0168,
          0.0168,
          0.0184,
          0.0184,
          0.0192,
          0.0192,
          0.02,
          0.02,
          0.0208,
          0.0208,
          0.0216,
          0.0216,
          0.0224,
          0.0224,
          0.0232,
          0.0232,
          0.024,
          0.024,
          0.0248,
          0.0248,
          0.0264,
          0.0264,
          0.0272,
          0.0272,
          0.028,
          0.028,
          0.0288,
          0.0288,
          0.0296,
          0.0296,
          0.0304,
          0.0304,
          0.0312,
          0.0312,
          0.0336,
          0.036,
          0.036,
          0.0368,
          0.0368,
          0.0408,
          0.0408,
          0.0432,
          0.0432,
          0.044,
          0.044,
          0.0448,
          0.0448,
          0.0456,
          0.0456,
          0.0464,
          0.0464,
          0.0496,
          0.0496,
          0.0536,
          0.0536,
          0.0544,
          0.0544,
          0.056,
          0.056,
          0.0648,
          0.0648,
          0.0656,
          0.0656,
          0.0672,
          0.0672,
          0.068,
          0.068,
          0.0768,
          0.0768,
          0.0832,
          0.0832,
          0.0888,
          0.0888,
          0.0936,
          0.0936,
          0.0968,
          0.0968,
          0.1008,
          0.1008,
          0.104,
          0.104,
          0.1048,
          0.1048,
          0.1088,
          0.1088,
          0.1248,
          0.1248,
          0.1264,
          0.1264,
          0.1336,
          0.1336,
          0.1352,
          0.1352,
          0.1768,
          0.1768,
          0.264,
          0.264,
          0.5488,
          0.5488,
          0.8528,
          0.8528,
          1.0
        ],
        "tpr": [
          0.0,
          0.0008,
          0.0336,
          0.0336,
          0.0824,
          0.0824,
          0.1736,
          0.1736,
          0.184,
          0.184,
          0.2008,
          0.2008,
          0.2312,
          0.2312,
          0.2688,
          0.2688,
          0.2768,
          0.2768,
          0.2784,
          0.28,
          0.34,
          0.34,
          0.3544,
          0.3544,
          0.3568,
          0.3568,
          0.3632,
          0.3632,
          0.3648,
          0.3824,
          0.384,
          0.3888,
          0.3888,
          0.412,
          0.412,
          0.4424,
          0.4424,
          0.4768,
          0.4768,
          0.4872,
          0.4872,
          0.4968,
          0.4968,
          0.4976,
          0.4976,
          0.5376,
          0.5376,
          0.5424,
          0.5424,
          0.6296,
          0.6296,
          0.648,
          0.648,
          0.6584,
          0.6584,
          0.6832,
          0.6832,
          0.692,
          0.692,
          0.7032,
          0.7032,
          0.756,
          0.756,
          0.7616,
          0.7616,
          0.8144,
          0.8144,
          0.8328,
          0.8328,
          0.8936,
          0.8936,
          0.904,
          0.904,
          0.908,
          0.908,
          0.9416,
          0.9416,
          0.944,
          0.944,
          0.9488,
          0.9488,
          0.9568,
          0.9648,
          0.9648,
          0.9672,
          0.9672,
          0.9688,
          0.9688,
          0.9696,
          0.9696,
          0.9728,
          0.9728,
          0.976,
          0.976,
          0.9768,
          0.9768,
          0.9792,
          0.9792,
          0.98,
          0.98,
          0.9808,
          0.9808,
          0.9816,
          0.9816,
          0.9824,
          0.9824,
          0.9832,
          0.9832,
          0.984,
          0.984,
          0.9848,
          0.9848,
          0.9856,
          0.9856,
          0.9864,
          0.9864,
          0.9872,
          0.9872,
          0.988,
          0.988,
          0.9888,
          0.9888,
          0.9896,
          0.9896,
          0.9904,
          0.9904,
          0.9912,
          0.9912,
          0.992,
          0.992,
          0.9928,
          0.9928,
          0.9936,
          0.9936,
          0.9944,
          0.9944,
          0.9952,
          0.9952,
          0.996,
          0.996,
          0.9968,
          0.9968,
          0.9976,
          0.9976,
          0.9984,
          0.9984,
          0.9992,
          0.9992,
          1.0,
          1.0
        ],
        "thresholds": [
          Infinity,
          0.5027592182159424,
          0.5009680390357971,
          0.5009666085243225,
          0.49957075715065,
          0.49952590465545654,
          0.49825698137283325,
          0.4982222020626068,
          0.4980659484863281,
          0.49806562066078186,
          0.49790534377098083,
          0.4979042112827301,
          0.4975142478942871,
          0.4975087344646454,
          0.4971006214618683,
          0.4970758259296417,
          0.4970078468322754,
          0.4970071017742157,
          0.4969976246356964,
          0.49699369072914124,
          0.49637487530708313,
          0.49637356400489807,
          0.49614161252975464,
          0.4961405098438263,
          0.49610915780067444,
          0.49608197808265686,
          0.4960031807422638,
          0.49600040912628174,
          0.49598997831344604,
          0.49580830335617065,
          0.4958060383796692,
          0.4957595765590668,
          0.49575817584991455,
          0.4955311715602875,
          0.49551236629486084,
          0.49523547291755676,
          0.49523502588272095,
          0.4949067234992981,
          0.49489840865135193,
          0.4948452115058899,
          0.4948391914367676,
          0.4947207570075989,
          0.4947192370891571,
          0.494718074798584,
          0.49470841884613037,
          0.4942643642425537,
          0.4942629039287567,
          0.4942115545272827,
          0.49421095848083496,
          0.49343448877334595,
          0.493421345949173,
          0.4932418167591095,
          0.49322566390037537,
          0.4931170642375946,
          0.49310848116874695,
          0.49285781383514404,
          0.49284878373146057,
          0.4927280843257904,
          0.49272391200065613,
          0.4925582706928253,
          0.49255529046058655,
          0.4919194281101227,
          0.4919193983078003,
          0.4918603301048279,
          0.4918401539325714,
          0.49122336506843567,
          0.49121972918510437,
          0.49096712470054626,
          0.49093905091285706,
          0.4899553954601288,
          0.48995354771614075,
          0.48973873257637024,
          0.4897371530532837,
          0.48964881896972656,
          0.48963433504104614,
          0.48858845233917236,
          0.48857221007347107,
          0.48847696185112,
          0.4884685277938843,
          0.48800885677337646,
          0.4879629611968994,
          0.4874878525733948,
          0.48748552799224854,
          0.4866578280925751,
          0.48619136214256287,
          0.4859943985939026,
          0.4850340187549591,
          0.4812943637371063,
          0.4803854525089264,
          0.47588270902633667,
          0.4704402685165405,
          0.4664939045906067,
          0.4626346826553345,
          0.46217992901802063,
          0.4613809287548065,
          0.46097204089164734,
          0.4478970170021057,
          0.44716188311576843,
          0.44559118151664734,
          0.44222956895828247,
          0.4408750534057617,
          0.436685174703598,
          0.4355931580066681,
          0.43553295731544495,
          0.43553075194358826,
          0.43279537558555603,
          0.42959678173065186,
          0.4047897756099701,
          0.40322524309158325,
          0.4028483033180237,
          0.4023807644844055,
          0.4016270339488983,
          0.40095898509025574,
          0.39455902576446533,
          0.39282989501953125,
          0.3645388185977936,
          0.36020076274871826,
          0.34376534819602966,
          0.3400569260120392,
          0.3244435787200928,
          0.3230172395706177,
          0.308935284614563,
          0.30852627754211426,
          0.30105486512184143,
          0.30064657330513,
          0.29136916995048523,
          0.28947150707244873,
          0.28395527601242065,
          0.279427170753479,
          0.2775813937187195,
          0.2747872471809387,
          0.2653868794441223,
          0.2623783349990845,
          0.20942392945289612,
          0.20412932336330414,
          0.19611799716949463,
          0.1951872855424881,
          0.17918334901332855,
          0.1785142421722412,
          0.17588475346565247,
          0.17551662027835846,
          0.09726786613464355,
          0.09724964946508408,
          0.02044394239783287,
          0.02013615518808365,
          0.00021264290262479335,
          0.0002046902955044061,
          5.256169970380142e-07,
          5.213804001868994e-07,
          7.275034524453772e-13
        ]
      },
      "roc_auc": 0.98335296,
      "optimal_threshold": 0.4478970170021057
    },
    "improvement": {
      "accuracy_improvement": 0.08511111111111103,
      "precision_improvement": 0.0837865716429107,
      "recall_improvement": 0.118,
      "f1_improvement": 0.0998301957083283,
      "mcc_improvement": 0,
      "zero_day_detection_improvement": 0.05555555555555558
    },
    "test_samples": 8178,
    "evaluated_samples": 8178,
    "meta_tasks_samples": 5000,
    "zero_day_samples": 4089,
    "timestamp": 1760177240.0795488
  },
  "incentive_history": [
    {
      "round_number": 1,
      "total_rewards": 334,
      "timestamp": 1760177170.0543766
    }
  ],
  "client_addresses": {
    "client_1": "0xCD3a95b26EA98a04934CCf6C766f9406496CA986",
    "client_2": "0x32cE285CF96cf83226552A9c3427Bd58c0A9AccD",
    "client_3": "0x8EbA3b47c80a5E31b4Ea6fED4d5De8ebc93B8d6f"
  },
  "timestamp": 1760177249.569134
}